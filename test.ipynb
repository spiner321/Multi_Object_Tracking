{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def img2label_paths(img_paths):\n",
    "    # Define label paths as a function of image paths\n",
    "    # sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels{os.sep}'  # /images/, /labels/ substrings #origin\n",
    "    sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels_yolo{os.sep}'  # /images/, /labels/ substrings\n",
    "    \n",
    "    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = os.listdir('/data/NIA50/50-2/data/NIA48/temp_data/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud on CPU:0 [64000 points (Float32)].\n",
       "Attributes: intensity (dtype = Float32, shape = {64000, 1})."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_f = o3d.t.io.read_point_cloud('/data/NIA50/SUSTechPOINTS_2-050/data/Suwon_A_0000/lidar/0000.pcd')\n",
    "bb\n",
    "pcd_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lidar_camera_calib(json_name, camera_mat, dist_coeff, lidar_points, image_points):\n",
    "    retval, rvec, tvec, inliers = cv2.solvePnPRansac(lidar_points, image_points, camera_mat, dist_coeff, iterationsCount=5000, reprojectionError=8.0)\n",
    "    print(\"-----\")\n",
    "    rot_mat, jac = cv2.Rodrigues(rvec)\n",
    "    print(rot_mat)\n",
    "    print(\"-----\")\n",
    "    print(tvec)\n",
    "    print(\"-----\")\n",
    "    rt = np.hstack((rot_mat, tvec))\n",
    "    T = np.vstack((rt, [[0,0,0,1]]))\n",
    "    print (T)\n",
    "    calib_json = {\n",
    "        \"extrinsic\": T.flatten().tolist(),\n",
    "        \"intrinsic\": camera_mat.flatten().tolist()\n",
    "    }\n",
    "    json_object = json.dumps(calib_json, indent = 4) \n",
    "    # Writing to sample.json \n",
    "    with open(json_name, \"w\") as outfile: \n",
    "        outfile.write(json_object) \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob, cv2\n",
    "\n",
    "# 종료 기준(termination criteria)를 정한다.\n",
    "criteria = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30 ,0.001)\n",
    "\n",
    "# Object Point(3D)를 준비한다. (0,0,0),(1,0,0),(2,0,0)... 처럼\n",
    "objp = np.zeros((6*7,3),np.float32)\n",
    "# np,mgrid[0:7,0:6]으로 (2,7,6) 배열 생성\n",
    "# Transpose 해줘서 (6,7,2)로, reshpae(-1,2)로 flat 시켜서 (42,2)로 변환\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# 이미지로 부터의 Object point와 Image points를 저장하기 위한 배열\n",
    "objpoints = [] # 실제 세계의 3D 점들 \n",
    "imgpoints = [] # 2D 이미지의 점들\n",
    "\n",
    "# 전체 path를 받기 위해 os말고 glob 사용\n",
    "images = glob.glob('./images/Calib/*.jpg')\n",
    "\n",
    "for name in images:\n",
    "    img = cv2.imread(name)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 체스판의 코너들 찾기\n",
    "    ret, corners = cv2.findChessboardCorners(gray,(7,6),None)\n",
    "\n",
    "    # 찾았으면, Object points, Image points 추가하기 (이후에 수정한다)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # 코너를 그리고 봐보자\n",
    "        img = cv2.drawChessboardCorners(img,(7,6),corners2,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 30, 0.001)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('spiner310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746d95b724613cc31ae9ea1c95fce8e51ec3ee7393c1b2a647745f061ae2ccda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
