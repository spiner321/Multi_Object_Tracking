{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def img2label_paths(img_paths):\n",
    "    # Define label paths as a function of image paths\n",
    "    # sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels{os.sep}'  # /images/, /labels/ substrings #origin\n",
    "    sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels_yolo{os.sep}'  # /images/, /labels/ substrings\n",
    "    \n",
    "    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = os.listdir('/data/NIA50/50-2/data/NIA48/temp_data/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# device = o3d.core.Device('cuda:1')\n",
    "pcd_f = o3d.t.io.read_point_cloud('/data/NIA50/SUSTechPOINTS_2-050/data/example/lidar/000965.pcd')\n",
    "print(pcd_f)\n",
    "\n",
    "positions = pcd_f.point.positions.numpy()\n",
    "intensity = pcd_f.point.intensity.numpy()\n",
    "pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "\n",
    "xyzi = np.stack([pcd[:,1]*-1, pcd[:, 0], pcd[:, 2], pcd[:, 3]], axis=1)\n",
    "\n",
    "# xyz = xyzi[:, :3]\n",
    "# i = [[i] for i in xyzi[:, 3]]\n",
    "\n",
    "# pcd = o3d.t.geometry.PointCloud()\n",
    "# pcd.point[\"positions\"] = o3d.core.Tensor(xyz)\n",
    "# pcd.point[\"intensity\"] = o3d.core.Tensor(i)\n",
    "\n",
    "# o3d.t.io.write_point_cloud('/data/NIA50/SUSTechPOINTS_2-050/data/example copy/lidar/000965.pcd', pcd, write_ascii=True)\n",
    "# np.frombuffer(pcd.tobytes(), dtype='float32').reshape(-1, 4) # bytes에서 numpy로 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lidar_camera_calib(json_name, camera_mat, dist_coeff, lidar_points, image_points):\n",
    "    retval, rvec, tvec, inliers = cv2.solvePnPRansac(lidar_points, image_points, camera_mat, dist_coeff, iterationsCount=5000, reprojectionError=8.0)\n",
    "    print(\"-----\")\n",
    "    rot_mat, jac = cv2.Rodrigues(rvec)\n",
    "    print(rot_mat)\n",
    "    print(\"-----\")\n",
    "    print(tvec)\n",
    "    print(\"-----\")\n",
    "    rt = np.hstack((rot_mat, tvec))\n",
    "    T = np.vstack((rt, [[0,0,0,1]]))\n",
    "    print (T)\n",
    "    calib_json = {\n",
    "        \"extrinsic\": T.flatten().tolist(),\n",
    "        \"intrinsic\": camera_mat.flatten().tolist()\n",
    "    }\n",
    "    json_object = json.dumps(calib_json, indent = 4) \n",
    "    # Writing to sample.json \n",
    "    with open(json_name, \"w\") as outfile: \n",
    "        outfile.write(json_object) \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob, cv2\n",
    "\n",
    "# 종료 기준(termination criteria)를 정한다.\n",
    "criteria = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30 ,0.001)\n",
    "\n",
    "# Object Point(3D)를 준비한다. (0,0,0),(1,0,0),(2,0,0)... 처럼\n",
    "objp = np.zeros((6*7,3),np.float32)\n",
    "# np,mgrid[0:7,0:6]으로 (2,7,6) 배열 생성\n",
    "# Transpose 해줘서 (6,7,2)로, reshpae(-1,2)로 flat 시켜서 (42,2)로 변환\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# 이미지로 부터의 Object point와 Image points를 저장하기 위한 배열\n",
    "objpoints = [] # 실제 세계의 3D 점들 \n",
    "imgpoints = [] # 2D 이미지의 점들\n",
    "\n",
    "# 전체 path를 받기 위해 os말고 glob 사용\n",
    "images = glob.glob('./images/Calib/*.jpg')\n",
    "\n",
    "for name in images:\n",
    "    img = cv2.imread(name)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 체스판의 코너들 찾기\n",
    "    ret, corners = cv2.findChessboardCorners(gray,(7,6),None)\n",
    "\n",
    "    # 찾았으면, Object points, Image points 추가하기 (이후에 수정한다)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # 코너를 그리고 봐보자\n",
    "        img = cv2.drawChessboardCorners(img,(7,6),corners2,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 30, 0.001)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle as pkl\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "# 문자열 숫자리스트로 바꾸는 함수\n",
    "def str2list(txt):\n",
    "    txt = txt.replace('\\n', '').split(',')\n",
    "    txt = list(map(float, txt))\n",
    "    \n",
    "    return txt\n",
    "\n",
    "\n",
    "# 리스트를 문자열로 바꾸는 함수\n",
    "def list2str(list):\n",
    "    list = ' '.join(map(str, list))\n",
    "    \n",
    "    return list\n",
    "\n",
    "\n",
    "# alpha 구하는 공식\n",
    "import math\n",
    "\n",
    "def normalizeAngle(angle):\n",
    "    result = angle % (2*math.pi)\n",
    "    if result < -math.pi:\n",
    "        result += 2*math.pi\n",
    "    elif result > math.pi:\n",
    "        result -= 2*math.pi\n",
    "    return result\n",
    "\n",
    "def cal_alpha_ori(x, z, ry):  \n",
    "    angle = ry\n",
    "    angle -= -math.atan2(z, x) -1.5*math.pi \n",
    "    alpha = normalizeAngle(angle)\n",
    "    return alpha # -1.818032754845337\n",
    "# cal_alpha_ori(2.5702, 9.7190, -1.5595)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[721.5   0.  609.6   0. ]\n",
      " [  0.  721.5 172.9   0. ]\n",
      " [  0.    0.    1.    0. ]] \n",
      "\n",
      "[[ 721.5    0.   609.6 -387.6]\n",
      " [   0.   721.5  172.9    0. ]\n",
      " [   0.     0.     1.     0. ]] \n",
      "\n",
      "[[7.215e+02 0.000e+00 6.096e+02 4.490e+01]\n",
      " [0.000e+00 7.215e+02 1.729e+02 2.000e-01]\n",
      " [0.000e+00 0.000e+00 1.000e+00 0.000e+00]] \n",
      "\n",
      "[[ 721.5    0.   609.6 -339.5]\n",
      " [   0.   721.5  172.9    2.2]\n",
      " [   0.     0.     1.     0. ]] \n",
      "\n",
      "[[ 0.9999239   0.00983776 -0.00744505]\n",
      " [-0.0098698   0.9999421  -0.00427846]\n",
      " [ 0.00740253  0.00435161  0.9999631 ]] \n",
      "\n",
      "[[ 7.533745e-03 -9.999714e-01 -6.166020e-04 -4.069766e-03]\n",
      " [ 1.480249e-02  7.280733e-04 -9.998902e-01 -7.631618e-02]\n",
      " [ 9.998621e-01  7.523790e-03  1.480755e-02 -2.717806e-01]] \n",
      "\n",
      "[[ 9.999976e-01  7.553071e-04 -2.035826e-03 -8.086759e-01]\n",
      " [-7.854027e-04  9.998898e-01 -1.482298e-02  3.195559e-01]\n",
      " [ 2.024406e-03  1.482454e-02  9.998881e-01 -7.997231e-01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('/data/hwang/datasets/kitti/training/calib/000055.txt', 'r') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "p0 = txt[0].replace('\\n', '').split(' ')[1:] # 0번 카메라, projection matrix (= intrinsic * extrinsic)\n",
    "p1 = txt[1].replace('\\n', '').split(' ')[1:] # 1번 카메라\n",
    "p2 = txt[2].replace('\\n', '').split(' ')[1:] # 2번 카메라 (모델에 이 정보를 사용), (i, 4)위치는 기본 카메라와의 위상 차이 (각 x, y, z 축)\n",
    "p3 = txt[3].replace('\\n', '').split(' ')[1:] # 3번 카메라\n",
    "R_rect = txt[4].replace('\\n', '').split(' ')[1:] # 스테레오 카메라로 촬영 시 rotation matrix 보정 수치 (모노 카메라면 단위행렬 사용)\n",
    "Tr_velo = txt[5].replace('\\n', '').split(' ')[1:] # extrinsic (사용은 rigid body transformation 형태로 사용, extrinsic 4행에 [0, 0, 0, 1]을 추가)\n",
    "Tr_imu = txt[6].replace('\\n', '').split(' ')[1:]\n",
    "\n",
    "print(np.around(np.asarray(p0, dtype=float).reshape(-1, 4), 1), '\\n')\n",
    "print(np.around(np.asarray(p1, dtype=float).reshape(-1, 4), 1), '\\n')\n",
    "print(np.around(np.asarray(p2, dtype=float).reshape(-1, 4), 1), '\\n')\n",
    "print(np.around(np.asarray(p3, dtype=float).reshape(-1, 4), 1), '\\n')\n",
    "print(np.asarray(R_rect, dtype=float).reshape(-1, 3), '\\n')\n",
    "print(np.asarray(Tr_velo, dtype=float).reshape(-1, 4), '\\n')\n",
    "print(np.asarray(Tr_imu, dtype=float).reshape(-1, 4), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open('/data/NIA50/SUSTechPOINTS_2-050/data/kitti/camera/front/000055.png').convert('RGB')\n",
    "\n",
    "im.save('/data/NIA50/SUSTechPOINTS_2-050/data/kitti/camera/front/000055.jpg', 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('spiner310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746d95b724613cc31ae9ea1c95fce8e51ec3ee7393c1b2a647745f061ae2ccda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
