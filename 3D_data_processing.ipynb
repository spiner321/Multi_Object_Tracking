{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 모듈 및 함수\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle as pkl\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "# 문자열 숫자리스트로 바꾸는 함수\n",
    "def str2list(txt):\n",
    "    txt = txt.replace('\\n', '').split(',')\n",
    "    txt = list(map(float, txt))\n",
    "    \n",
    "    return txt\n",
    "\n",
    "\n",
    "# 리스트를 문자열로 바꾸는 함수\n",
    "def list2str(list):\n",
    "    list = ' '.join(map(str, list))\n",
    "    \n",
    "    return list\n",
    "\n",
    "\n",
    "# alpha 구하는 공식\n",
    "import math\n",
    "\n",
    "def normalizeAngle(angle):\n",
    "    result = angle % (2*math.pi)\n",
    "    if result < -math.pi:\n",
    "        result += 2*math.pi\n",
    "    elif result > math.pi:\n",
    "        result -= 2*math.pi\n",
    "    return result\n",
    "\n",
    "def cal_alpha_ori(x, z, ry):  \n",
    "    angle = ry\n",
    "    angle -= -math.atan2(z, x) -1.5*math.pi \n",
    "    alpha = normalizeAngle(angle)\n",
    "    return alpha # -1.818032754845337\n",
    "# cal_alpha_ori(2.5702, 9.7190, -1.5595)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # kitti dataset calib 확인\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/hwang/datasets/kitti/training/calib/000000.txt', 'r') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "p0 = txt[0].replace('\\n', '').split(' ')[1:] # 0번 카메라, projection matrix (= intrinsic * extrinsic)\n",
    "p1 = txt[1].replace('\\n', '').split(' ')[1:] # 1번 카메라\n",
    "p2 = txt[2].replace('\\n', '').split(' ')[1:] # 2번 카메라 (모델에 이 정보를 사용), (i, 4)위치는 기본 카메라와의 위상 차이 (각 x, y, z 축)\n",
    "p3 = txt[3].replace('\\n', '').split(' ')[1:] # 3번 카메라\n",
    "R_rect = txt[4].replace('\\n', '').split(' ')[1:] # 스테레오 카메라로 촬영 시 rotation matrix 보정 수치 (모노 카메라면 단위행렬 사용)\n",
    "Tr_velo = txt[5].replace('\\n', '').split(' ')[1:] # extrinsic (사용은 rigid body transformation 형태로 사용, extrinsic 4행에 [0, 0, 0, 1]을 추가)\n",
    "Tr_imu = txt[6].replace('\\n', '').split(' ')[1:]\n",
    "\n",
    "print(np.around(np.asarray(p0, dtype=float).reshape(-1, 4), 1), '\\n')\n",
    "print(np.around(np.asarray(p1, dtype=float).reshape(-1, 4), 1), '\\n')\n",
    "print(np.around(np.asarray(p2, dtype=float).reshape(-1, 4), 1), '\\n')\n",
    "print(np.around(np.asarray(p3, dtype=float).reshape(-1, 4), 1), '\\n')\n",
    "print(np.asarray(R_rect, dtype=float).reshape(-1, 3), '\\n')\n",
    "print(np.asarray(Tr_velo, dtype=float).reshape(-1, 4), '\\n')\n",
    "print(np.asarray(Tr_imu, dtype=float).reshape(-1, 4), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_json = {\n",
    "    \"extrinsic\": np.asarray(Tr_velo, dtype=np.float32).tolist(),\n",
    "    \"intrinsic\": np.asarray(p2, dtype=np.float32).reshape(-1, 4)[:3, :3].flatten().tolist()\n",
    "}\n",
    "json_object = json.dumps(calib_json, indent = 4) \n",
    "# Writing to sample.json \n",
    "with open('/data/NIA50/SUSTechPOINTS_2-050/data/nia48/calib/000055.json', \"w\") as outfile: \n",
    "    outfile.write(json_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = np.asarray(Tr_velo, dtype=float).reshape(3, -1)[:3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.from_matrix(rt).as_euler('xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tr_velo = np.asarray(Tr_velo, dtype=float).reshape(3, 4)[:, :3]\n",
    "R_rect = np.asarray(R_rect, dtype=float).reshape(3, 3)\n",
    "\n",
    "# np.matmul(Tr_velo, R_rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_path = '/data/hwang/datasets/kitti/training/calib/'\n",
    "frame = '000000'\n",
    "\n",
    "def get_inv_matrix(file, v2c, rect):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        trans = [x for x in filter(lambda s: s.startswith(v2c), lines)][0]\n",
    "        \n",
    "        matrix = [m for m in map(lambda x: float(x), trans.strip().split(\" \")[1:])]\n",
    "        matrix = matrix + [0,0,0,1]\n",
    "        m = np.array(matrix)\n",
    "        velo_to_cam  = m.reshape([4,4])\n",
    "\n",
    "\n",
    "        trans = [x for x in filter(lambda s: s.startswith(rect), lines)][0]\n",
    "        matrix = [m for m in map(lambda x: float(x), trans.strip().split(\" \")[1:])]        \n",
    "        m = np.array(matrix).reshape(3,3)\n",
    "        \n",
    "        m = np.concatenate((m, np.expand_dims(np.zeros(3), 1)), axis=1)\n",
    "        \n",
    "        rect = np.concatenate((m, np.expand_dims(np.array([0,0,0,1]), 0)), axis=0)        \n",
    "        \n",
    "        # print(velo_to_cam, rect)    \n",
    "        m = np.matmul(rect, velo_to_cam)\n",
    "\n",
    "\n",
    "        m = np.linalg.inv(m)\n",
    "        \n",
    "        return m\n",
    "        \n",
    "def get_detection_inv_matrix(calib_path, frame):\n",
    "    file = os.path.join(calib_path, frame+\".txt\")\n",
    "    return get_inv_matrix(file, \"Tr_velo_to_cam\", \"R0_rect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # convert pcd - npy\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # pcd to npy\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = o3d.core.Device('cuda:1')\n",
    "pcd_f = o3d.t.io.read_point_cloud('/data/NIA50/SUSTechPOINTS_2-050/data/Suwon_A_0000/lidar/0000.pcd')\n",
    "print(pcd_f)\n",
    "\n",
    "positions = pcd_f.point.positions.numpy()\n",
    "intensity = pcd_f.point.intensity.numpy()\n",
    "pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "\n",
    "pcd\n",
    "\n",
    "# np.frombuffer(pcd.tobytes(), dtype='float32').reshape(-1, 4) # bytes에서 numpy로 복원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # npy to pcd\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_f = o3d.t.io.read_point_cloud('/data/NIA50/SUSTechPOINTS_2-050/data/Suwon_A_0000/lidar/0000.pcd')\n",
    "\n",
    "positions = pcd_f.point.positions.numpy()\n",
    "intensity = pcd_f.point.intensity.numpy()\n",
    "pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "\n",
    "xyzi = np.stack([pcd[:,1]*-1, pcd[:, 0], pcd[:, 2], pcd[:, 3]], axis=1)\n",
    "\n",
    "xyz = xyzi[:, :3]\n",
    "i = [[i] for i in xyzi[:, 3]]\n",
    "\n",
    "pcd = o3d.t.geometry.PointCloud()\n",
    "pcd.point[\"positions\"] = o3d.core.Tensor(xyz)\n",
    "pcd.point[\"intensity\"] = o3d.core.Tensor(i)\n",
    "\n",
    "o3d.t.io.write_point_cloud('/data/NIA50/SUSTechPOINTS_2-050/data/Suwon_A_0000/lidar/0011.pcd', pcd, write_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzi = np.fromfile('/data/hwang/datasets/kitti/training/velodyne/000000.bin', dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "xyz = xyzi[:, :3]\n",
    "i = [[i] for i in xyzi[:, 3]]\n",
    "\n",
    "pcd = o3d.t.geometry.PointCloud()\n",
    "pcd.point[\"positions\"] = o3d.core.Tensor(xyz)\n",
    "pcd.point[\"intensity\"] = o3d.core.Tensor(i)\n",
    "\n",
    "o3d.t.io.write_point_cloud('/data/NIA50/SUSTechPOINTS_2-050/data/Suwon_A_0000/lidar/0010.pcd', pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Fundamental Matrix\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python # cv2.xfeatures2d.sift_create()를 사용하기 위해서는 따로 설치 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 이미지 사이에 매칭되는 특징점을 최대한 많이 찾아내야 한다.\n",
    "# FLANN에 기반한 매처를 이용한 SIFT 디스크립터를 사용하고 ratio를 테스트한다.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('/data/NIA50/50-2/data/NIA48/fine_data/S_Clip_02244_02/Camera/CameraFront/blur/2-048_02244_CF_001.png')\n",
    "img2 = cv2.imread('/data/NIA50/50-2/data/NIA48/fine_data/S_Clip_02244_02/Camera/CameraFront/blur/2-048_02244_CF_032.png')\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = {'algorithm': FLANN_INDEX_KDTREE, 'trees': 5}\n",
    "search_params = {'check': 50}\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "good = []\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "\n",
    "# ratio test as per Lowe's paper\n",
    "for i, (m, n) in enumerate(matches):\n",
    "    if m.distance < 0.8*n.distance:\n",
    "        good.append(m)\n",
    "        pts2.append(kp2[m.trainIdx].pt)\n",
    "        pts1.append(kp1[m.queryIdx].pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 이미지로부터 매칭되는 특징점 중 가장 좋은 것들을 이용해 Fundamental Matrix를 계산한다.\n",
    "\n",
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_LMEDS)\n",
    "\n",
    "# We select only inlier points\n",
    "pts1 = pts1[mask.ravel()==1]\n",
    "pts2 = pts2[mask.ravel()==1]\n",
    "\n",
    "# Fundamental Matrix\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epiline 찾기\n",
    "\n",
    "def drawlines(img1, img2, lines, pts1, pts2):\n",
    "    '''img1 - image on which we draw epilines for the points in img2 \\n\n",
    "    lines - corresponding epilines'''    \n",
    "    \n",
    "    r, c, _ = img1.shape\n",
    "    # img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    # img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    for r, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), color, 1)\n",
    "        img1 = cv2.circle(img1, tuple(pt1), 5, color, -1)\n",
    "        img2 = cv2.circle(img2, tuple(pt2), 5, color, -1)\n",
    "        \n",
    "    return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epiline을 찾아 그려준다.\n",
    "\n",
    "# Find epilines corresponding to points in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n",
    "lines1 = lines1.reshape(-1,3)\n",
    "img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n",
    "lines2 = lines2.reshape(-1,3)\n",
    "img3,img4 = drawlines(img2, img1, lines2, pts2, pts1)\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(121),plt.imshow(img5)\n",
    "plt.subplot(122),plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(F, 3)xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Essential Matrix\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, mask = cv2.findEssentialMat(points1=pts1, \n",
    "                               points2=pts2, \n",
    "                               cameraMatrix=intrinsic[:3, :3],\n",
    "                               method = cv2.RANSAC,\n",
    "                               prob = 0.999,\n",
    "                               threshold = 1.0)\n",
    "\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(np.matmul(E, F), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, r, t, _ = cv2.recoverPose(E, pts1, pts2, intrinsic[:3, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.around(E, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 특수환경 자율주행 3D 이미지\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # make dataframe\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색용 코드\n",
    "df.loc[df['xyzlwh'].apply(lambda x: -31.16 in x[:3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=['clip', 'frame', 'xyxy', 'xyzlwh', 'theta', 'eulerangle', 'translation', 'fxfycxcy', 'k1k2p1p2', 'pcd', 'class'])\n",
    "idx = 0\n",
    "\n",
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/training/'\n",
    "clips = sorted([i for i in os.listdir(path) if 'drive_' in i])\n",
    "# clip = clips[20]\n",
    "\n",
    "for clip in clips:\n",
    "    try:\n",
    "        with open(path+clip+'/calib.txt', 'r') as f:\n",
    "            calib = [re.sub('\\n', '', i) for i in f.readlines()]\n",
    "\n",
    "        eulerangle = calib[4].split(',')\n",
    "        translation = calib[6].split(',')\n",
    "        intrinsic = calib[8].split(',')\n",
    "        fxfycxcy = intrinsic[:4]\n",
    "        k1k2p1p2 = intrinsic[4:]\n",
    "\n",
    "        metas = sorted(os.listdir(path+clip+'/meta/'))\n",
    "\n",
    "        for meta in metas:\n",
    "            meta = path+clip+f'/meta/{meta}'\n",
    "            frame = meta[-11:-5]\n",
    "\n",
    "            pcd_f = o3d.t.io.read_point_cloud(path+clip+f'/lidar/{clip}_{frame}.pcd')\n",
    "            positions = pcd_f.point.positions.numpy()\n",
    "            intensity = pcd_f.point.intensity.numpy()\n",
    "            pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "\n",
    "            with open(meta, 'r') as f:\n",
    "                meta_js = json.load(f)\n",
    "\n",
    "            objects = meta_js['OBJECT_LIST'][0]['3D_LIST']\n",
    "            for i in range(len(objects)):\n",
    "                object = objects[i]\n",
    "                xyxy = object['BOX']\n",
    "                xyz = object['LOCATION']\n",
    "                hwl = object['DIMENSION']\n",
    "                xyzlwh = xyz + hwl[2:3] + hwl[1:2] + hwl[0:1]\n",
    "                # xyzlwh = ', '.join(map(str, xyzlwh))\n",
    "                theta = object['YAW']\n",
    "                class_ = object['TYPE']\n",
    "\n",
    "                train_df.loc[idx] = [clip, frame, xyxy, xyzlwh, theta, eulerangle, translation, fxfycxcy, k1k2p1p2, pcd, class_]\n",
    "\n",
    "                idx+=1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    train_df.to_csv('/data/NIA50/data/특수환경 자율주행 3D 이미지/train_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # validation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(columns=['clip', 'frame', 'xyxy', 'xyzlwh', 'theta', 'eulerangle', 'translation', 'fxfycxcy', 'k1k2p1p2', 'class', 'type'])\n",
    "idx = 0\n",
    "\n",
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/Validation/'\n",
    "clips = sorted([i for i in os.listdir(path) if 'drive_' in i])\n",
    "# clip = clips[20]\n",
    "\n",
    "for clip in clips:\n",
    "    try:\n",
    "        with open(path+clip+'/calib.txt', 'r') as f:\n",
    "            calib = [re.sub('\\n', '', i) for i in f.readlines()]\n",
    "\n",
    "        eulerangle = list(map(float, calib[4].split(',')))\n",
    "        translation = list(map(float, calib[6].split(',')))\n",
    "        intrinsic = list(map(float, calib[8].split(',')))\n",
    "        fxfycxcy = intrinsic[:4]\n",
    "        k1k2p1p2 = intrinsic[4:]\n",
    "\n",
    "        metas = sorted(os.listdir(path+clip+'/lidar/'))\n",
    "\n",
    "        for meta in metas:\n",
    "            meta = path+clip+f'/meta/{meta}'\n",
    "            frame = meta[-11:-5]\n",
    "\n",
    "            # pcd_f = o3d.t.io.read_point_cloud(path+clip+f'/lidar/{clip}_{frame}.pcd')\n",
    "            # positions = pcd_f.point.positions.numpy()\n",
    "            # intensity = pcd_f.point.intensity.numpy()\n",
    "            # pcd = np.concatenate((positions, intensity), axis = 1).tobytes()\n",
    "\n",
    "            with open(meta, 'r') as f:\n",
    "                meta_js = json.load(f)\n",
    "\n",
    "            objects = meta_js['OBJECT_LIST'][0]['3D_LIST']\n",
    "            for i in range(len(objects)):\n",
    "                object = objects[i]\n",
    "                xyxy = object['BOX']\n",
    "                xyz = object['LOCATION']\n",
    "                hwl = object['DIMENSION']\n",
    "                xyzlwh = xyz + hwl[2:3] + hwl[1:2] + hwl[0:1]\n",
    "                # xyzlwh = ', '.join(map(str, xyzlwh))\n",
    "                theta = object['YAW']\n",
    "                class_ = object['CLASS']\n",
    "                type_ = object['TYPE']\n",
    "\n",
    "                val_df.loc[idx] = [clip, frame, xyxy, xyzlwh, theta, eulerangle, translation, fxfycxcy, k1k2p1p2, class_, type_]\n",
    "\n",
    "                idx+=1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    val_df.to_csv('/data/NIA50/data/특수환경 자율주행 3D 이미지/val_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # PV-RCNN (fit custom dataset)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # save npy\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('/data/NIA50/data/특수환경 자율주행 3D 이미지/val_df.csv')\n",
    "val_df['frame'] = val_df['frame'].apply(lambda x: str(x).zfill(6))\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/Validation/'\n",
    "save_path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/points'\n",
    "\n",
    "true_data = val_df.loc[val_df['xyzlwh']!='[0.0, 0.0, 0.0, 0, 0, 0]']\n",
    "clips = true_data['clip'].unique()\n",
    "\n",
    "for clip in clips:\n",
    "    frames = true_data.loc[true_data['clip'] == clip, 'frame'].unique()\n",
    "\n",
    "    for frame in frames:\n",
    "        try:\n",
    "            pcd_name = pcd_name = clip + f'_{frame}.pcd'\n",
    "            pcd_f = o3d.t.io.read_point_cloud(path+clip+'/lidar/'+pcd_name)\n",
    "\n",
    "            positions = pcd_f.point.positions.numpy()\n",
    "            intensity = pcd_f.point.intensity.numpy()\n",
    "            pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "\n",
    "            npy = np.save(save_path+f'/{clip}_{frame}.npy', pcd)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/ImageSets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # dividing train, val\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # imagesets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('/data/NIA50/data/특수환경 자율주행 3D 이미지/val_df.csv')\n",
    "val_df['frame'] = val_df['frame'].apply(lambda x: str(x).zfill(6))\n",
    "tdf = val_df.loc[val_df['xyzlwh']!='[0.0, 0.0, 0.0, 0, 0, 0]']\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "clips = tdf['clip'].unique()\n",
    "for clip in clips:\n",
    "\n",
    "    frames = tdf.loc[tdf['clip'] == clip, 'frame'].unique()\n",
    "    for frame in frames:\n",
    "        image = clip+f'_{frame}'\n",
    "        images.append(image)\n",
    "\n",
    "len(images), len(os.listdir('/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/points'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted([re.sub('.npy', '', i) for i in os.listdir('/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/points')])\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/ImageSets/'\n",
    "\n",
    "train, val = train_test_split(images, test_size=0.2, random_state=0)\n",
    "\n",
    "with open(path+'train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(train)))\n",
    "\n",
    "with open(path+'val.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # labels\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차집합\n",
    "\n",
    "set(labels) - set(images)\n",
    "set(labels).difference(set(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/labels/'\n",
    "labels = [re.sub('.txt', '', i) for i in os.listdir(path)]\n",
    "\n",
    "for n_pcd in set(labels) - set(images):\n",
    "    if os.path.exists(path+f'{n_pcd}.txt'):\n",
    "        os.remove(path+f'{n_pcd}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # calibration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/calib/'\n",
    "\n",
    "clips = tdf['clip'].unique()\n",
    "for clip in clips:\n",
    "\n",
    "    frames = tdf.loc[tdf['clip'] == clip, 'frame'].unique()\n",
    "    for frame in frames:\n",
    "        image = clip+f'_{frame}'\n",
    "\n",
    "        fxfycxcy = json.loads(tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame), 'fxfycxcy'].values[0])\n",
    "        eulerangle = json.loads(tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame), 'eulerangle'].values[0])\n",
    "        translation = json.loads(tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame), 'translation'].values[0])\n",
    "        intrinsic = np.asarray([[fxfycxcy[0], 0, fxfycxcy[2]], [0, fxfycxcy[1], fxfycxcy[3]], [0, 0, 1]])\n",
    "        rotation_matrix = R.from_euler('xyz', eulerangle, degrees=True).as_matrix()\n",
    "\n",
    "        p0 = np.hstack([intrinsic, np.zeros((3, 1))])\n",
    "        R0_rect = np.eye(3)\n",
    "        Tr_velo_to_cam = np.hstack([rotation_matrix, np.asarray(translation).reshape(3, -1)])\n",
    "        Tr_imu_to_velo = np.zeros((12))\n",
    "\n",
    "        # to string\n",
    "        p0 = ' '.join(map(str, p0.reshape(-1).tolist()))\n",
    "        p1 = p0\n",
    "        p2 = p0\n",
    "        p3 = p0\n",
    "        R0_rect = ' '.join(map(str, R0_rect.reshape(-1).tolist()))\n",
    "        Tr_velo_to_cam = ' '.join(map(str, Tr_velo_to_cam.reshape(-1).tolist()))\n",
    "        Tr_imu_to_velo = ' '.join(map(str, Tr_imu_to_velo.reshape(-1).tolist()))\n",
    "\n",
    "        label_lines = ['P0: '+p0, 'P1: '+p1, 'P2: '+p2, 'P3: '+p3, 'R0_rect: '+R0_rect, 'Tr_velo_to_cam: '+Tr_velo_to_cam, 'Tr_imu_to_velo: '+Tr_imu_to_velo]\n",
    "        with open(path + f'{image}.txt', 'w') as f:\n",
    "            f.write('\\n'.join(label_lines))\n",
    "\n",
    "            # f.write(f'P0: {p0}\\n')\n",
    "            # f.write(f'P1: {p1}\\n')\n",
    "            # f.write(f'P2: {p2}\\n')\n",
    "            # f.write(f'P3: {p3}\\n')\n",
    "            # f.write(f'R0_rect: {R0_rect}\\n')\n",
    "            # f.write(f'Tr_velo_to_cam: {Tr_velo_to_cam}\\n')\n",
    "            # f.write(f'Tr_imu_to_velo: {Tr_imu_to_velo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/calib/'\n",
    "labels = [re.sub('.txt', '', i) for i in os.listdir(path)]\n",
    "\n",
    "for n_pcd in set(labels) - set(images):\n",
    "    if os.path.exists(path+f'{n_pcd}.txt'):\n",
    "        os.remove(path+f'{n_pcd}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # PointRCNN (fit kitti datset)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('/data/NIA50/data/특수환경 자율주행 3D 이미지/val_df.csv')\n",
    "val_df['frame'] = val_df['frame'].apply(lambda x: str(x).zfill(6))\n",
    "images = []\n",
    "for i in val_df.index.values:\n",
    "    image = val_df.loc[i]['clip'] + '_' + val_df.loc[i]['frame']\n",
    "    images.append(image)\n",
    "val_df['image'] = images\n",
    "tdf = val_df.loc[val_df['xyzlwh']!='[0.0, 0.0, 0.0, 0, 0, 0]']\n",
    "tdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # imagesets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 복사\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "exi_pcd = glob.glob('/data/NIA50/data/특수환경 자율주행 3D 이미지/Validation/*/lidar/*.pcd')\n",
    "exi_pcd = [i[-21:-4] for i in exi_pcd]\n",
    "\n",
    "images_true = []\n",
    "for clip in tdf['clip'].unique():\n",
    "    for frame in tdf.loc[tdf['clip'] == clip, 'frame'].unique():\n",
    "        image = clip + f'_{frame}'\n",
    "        images_true.append(image)\n",
    "        \n",
    "images = sorted(set(images_true) & set(exi_pcd))\n",
    "# images = sorted([re.sub('.npy', '', i) for i in os.listdir('/data/NIA50/data/특수환경 자율주행 3D 이미지/mm_Train3D/points')])\n",
    "\n",
    "images_re, test = train_test_split(images, test_size = 0.1, random_state = 0)\n",
    "train, val = train_test_split(images_re, test_size = 0.2, random_state = 0)\n",
    "\n",
    "path = '/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/imagesets/'\n",
    "\n",
    "# with open(path+'train.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(sorted(train)))\n",
    "\n",
    "# with open(path+'val.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(sorted(val)))\n",
    "    \n",
    "# with open(path+'test.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(sorted(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # velodyne\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_files = glob.glob('/data/NIA50/data/특수환경 자율주행 3D 이미지/Validation/*/lidar/*.pcd')\n",
    "\n",
    "pcd_path = []\n",
    "for pcd_file in pcd_files:\n",
    "    for image in images:\n",
    "        if image == pcd_file[-21:-4]:\n",
    "            pcd_path.append(pcd_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/velodyne', exist_ok=True)\n",
    "os.makedirs('/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/testing/velodyne', exist_ok=True)\n",
    "\n",
    "for pcd_file in pcd_path:\n",
    "    pcd_f = o3d.t.io.read_point_cloud(pcd_file)\n",
    "    positions = pcd_f.point.positions.numpy()\n",
    "    intensity = pcd_f.point.intensity.numpy()\n",
    "    \n",
    "    pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "    pcd_bytes = pcd.tobytes()\n",
    "    \n",
    "    if pcd_file[-21:-4] in train:\n",
    "        with open(f'/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/velodyne/{pcd_file[-21:-4]}.bin', 'wb') as f:\n",
    "            f.write(pcd_bytes)\n",
    "            \n",
    "    elif pcd_file[-21:-4] in val:\n",
    "        with open(f'/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/velodyne/{pcd_file[-21:-4]}.bin', 'wb') as f:\n",
    "            f.write(pcd_bytes)\n",
    "\n",
    "    elif pcd_file[-21:-4] in test:\n",
    "        with open(f'/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/testing/velodyne/{pcd_file[-21:-4]}.bin', 'wb') as f:\n",
    "            f.write(pcd_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # calib\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray([[0, 1, 0],\n",
    "            [0, 0, 1],\n",
    "            [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "clips = tdf['clip'].unique()\n",
    "for clip in clips[:1]:\n",
    "\n",
    "    frames = tdf.loc[tdf['clip'] == clip, 'frame'].unique()\n",
    "    for frame in frames:\n",
    "        image = clip+f'_{frame}'\n",
    "\n",
    "        fxfycxcy = json.loads(tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame), 'fxfycxcy'].values[0])\n",
    "        # eulerangle = json.loads(tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame), 'eulerangle'].values[0]) * np.asarray(180/np.pi)\n",
    "        eulerangle = json.loads(tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame), 'eulerangle'].values[0])\n",
    "        translation = json.loads(tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame), 'translation'].values[0])\n",
    "        intrinsic = np.asarray([[fxfycxcy[0], 0, fxfycxcy[2]], [0, fxfycxcy[1], fxfycxcy[3]], [0, 0, 1]])\n",
    "        rotation_matrix = R.from_euler('xyz', eulerangle, degrees=True).as_matrix()\n",
    "\n",
    "        p0 = np.hstack([intrinsic, np.zeros((3, 1))])\n",
    "        R0_rect = np.eye(3)\n",
    "        # velo_to_cam_rotation = np.asarray([[0, 1, 0],\n",
    "        #                                    [0, 0, 1],\n",
    "        #                                    [1, 0, 0]])\n",
    "        Tr_velo_to_cam = np.hstack([rotation_matrix, np.asarray(translation).reshape(3, -1)])\n",
    "        Tr_imu_to_velo = np.zeros((12))\n",
    "\n",
    "        # to string\n",
    "        p0 = ' '.join(map(str, p0.reshape(-1).tolist()))\n",
    "        p1 = p0\n",
    "        p2 = p0\n",
    "        p3 = p0\n",
    "        R0_rect = ' '.join(map(str, R0_rect.reshape(-1).tolist()))\n",
    "        # R0_rect = ' '.join(map(str, rotation_matrix.reshape(-1).tolist()))\n",
    "        Tr_velo_to_cam = ' '.join(map(str, Tr_velo_to_cam.reshape(-1).tolist()))\n",
    "        Tr_imu_to_velo = ' '.join(map(str, Tr_imu_to_velo.reshape(-1).tolist()))\n",
    "\n",
    "        label_lines = ['P0: '+p0, 'P1: '+p1, 'P2: '+p2, 'P3: '+p3, 'R0_rect: '+R0_rect, 'Tr_velo_to_cam: '+Tr_velo_to_cam, 'Tr_imu_to_velo: '+Tr_imu_to_velo]\n",
    "                \n",
    "        # if image in train:\n",
    "        #     with open('/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/calib/' + f'{image}.txt', 'w') as f:\n",
    "        #         f.write('\\n'.join(label_lines))\n",
    "                \n",
    "        if image in sorted(val)[:1]:\n",
    "            with open('/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/calib/' + f'{image}.txt', 'w') as f:\n",
    "                f.write('\\n'.join(label_lines))\n",
    "                \n",
    "        # elif image in test:\n",
    "        #     with open('/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/testing/calib/' + f'{image}.txt', 'w') as f:\n",
    "        #         f.write('\\n'.join(label_lines))\n",
    "                \n",
    "            # f.write(f'P0: {p0}\\n')\n",
    "            # f.write(f'P1: {p1}\\n')\n",
    "            # f.write(f'P2: {p2}\\n')\n",
    "            # f.write(f'P3: {p3}\\n')\n",
    "            # f.write(f'R0_rect: {R0_rect}\\n')\n",
    "            # f.write(f'Tr_velo_to_cam: {Tr_velo_to_cam}\\n')\n",
    "            # f.write(f'Tr_imu_to_velo: {Tr_imu_to_velo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # label_2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 구하는 공식\n",
    "\n",
    "import math\n",
    "\n",
    "def normalizeAngle(angle):\n",
    "    result = angle % (2*math.pi)\n",
    "    if result < -math.pi:\n",
    "        result += 2*math.pi\n",
    "    elif result > math.pi:\n",
    "        result -= 2*math.pi\n",
    "    return result\n",
    "\n",
    "def cal_alpha_ori(x, z, ry):  \n",
    "    angle = ry\n",
    "    angle -= -math.atan2(z, x) -1.5*math.pi \n",
    "    alpha = normalizeAngle(angle)\n",
    "    return alpha # -1.818032754845337\n",
    "\n",
    "cal_alpha_ori(2.5702, 9.7190, -1.5595)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/label_2', exist_ok=True)\n",
    "\n",
    "idx = tdf.index.values\n",
    "\n",
    "for i in idx[:1]:\n",
    "    clip = tdf.loc[i]['clip']\n",
    "    frame = tdf.loc[i]['frame']\n",
    "    image = clip + f'_{frame}'\n",
    "    \n",
    "    type_ = tdf.loc[i]['class']\n",
    "    truncation = 0.00\n",
    "    occulsion = 0\n",
    "    xyxy = json.loads(tdf.loc[i]['xyxy'])\n",
    "    xyzlwh = json.loads(tdf.loc[i]['xyzlwh'])\n",
    "    hwlxyz = [xyzlwh[5], xyzlwh[4], xyzlwh[3], xyzlwh[0], xyzlwh[1], xyzlwh[2]]\n",
    "    rotation_y = tdf.loc[i]['theta'] # rotation_y = theta\n",
    "    alpha = np.around(cal_alpha_ori(xyzlwh[0]*-1, xyzlwh[2], rotation_y), 2)\n",
    "    \n",
    "    if type_ == 'VEHICLE': type_ = 'Car'\n",
    "    elif type_ == 'BICYCLE': type_ = 'Cyclist'\n",
    "    elif type_ == 'PEDESTRIAN': type_ = 'Pedestrian'\n",
    "    \n",
    "    if xyxy[0] < 0: xyxy[0] = 0\n",
    "    if xyxy[1] < 0: xyxy[1] = 0\n",
    "    if xyxy[2] > 1920: xyxy[2] = 1920\n",
    "    if xyxy[3] > 1200: xyxy[3] = 1200\n",
    "    \n",
    "    xyxy = ' '.join(map(str, xyxy))\n",
    "    hwlxyz = ' '.join(map(str, hwlxyz))\n",
    "    \n",
    "    label = list(map(str, [type_, truncation, occulsion, alpha, xyxy, hwlxyz, rotation_y]))\n",
    "    \n",
    "    if image in train + val:\n",
    "        with open(f'/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/label_2/{image}.txt', 'w') as f:\n",
    "            f.write(' '.join(label))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clips = tdf['clip'].unique()\n",
    "# for clip in clips[:1]:\n",
    "    \n",
    "#     frames = tdf.loc[tdf['clip']==clip, 'frame'].unique()\n",
    "#     for frame in frames:\n",
    "        \n",
    "#         image = clip+f'_{frame}'\n",
    "#         for idx in len(tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame))\n",
    "#         class_ = tdf.loc[(tdf['clip']==clip) & (tdf['frame']==frame), 'class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # image_2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/image_2', exist_ok=True)\n",
    "os.makedirs('/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/testing/image_2', exist_ok=True)\n",
    "\n",
    "for train_img in train + val:\n",
    "    copy_path = glob.glob(f'/data/NIA50/data/특수환경 자율주행 3D 이미지/Validation/*/image_0/{train_img}.jpg')[0]\n",
    "    paste_path = f'/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/training/image_2/{train_img}.jpg'\n",
    "    shutil.copy(copy_path, paste_path)\n",
    "    \n",
    "# for test_img in test:\n",
    "#     copy_path = glob.glob(f'/data/NIA50/data/특수환경 자율주행 3D 이미지/Validation/*/image_0/{test_img}.jpg')[0]\n",
    "#     paste_path = f'/data/NIA50/data/특수환경 자율주행 3D 이미지/pointrcnn_Train3D/testing/image_2/{test_img}.jpg'\n",
    "#     shutil.copy(copy_path, paste_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # NIA48\n",
    "---\n",
    "- PointRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_and_resized_intrinsic(\n",
    "    fx, fy, cx, cy, crop_cx, crop_cy, resize_fx, resize_fy):\n",
    "    '''\n",
    "    crop_cx : crop size of u axis orientation in image plane\n",
    "    crop_cy : crop size of v axis orientation in image plane\n",
    "    resize_fx : resize ratio of width orientation in image plane\n",
    "    resize_fy : resize ratio of height orientation in image plane    \n",
    "    '''\n",
    "\n",
    "    cx -= crop_cx\n",
    "    cy -= crop_cy\n",
    "\n",
    "    fx *= resize_fx\n",
    "    fy *= resize_fy\n",
    "\n",
    "    cx *= resize_fx\n",
    "    cy *= resize_fy\n",
    "\n",
    "    return fx, fy, cx, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "735, 575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1200/575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_fpd = get_cropped_and_resized_intrinsic(fpd[0], fpd[1], fpd[2], fpd[3], 0, 0, 1920/735, 1200/575)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1920 / 735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 숫자리스트로 바꾸는 함수\n",
    "def str_cng(txt):\n",
    "    txt = txt.replace('\\n', '').split(',')\n",
    "    txt = list(map(float, txt))\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # calib\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '/data/NIA50/50-2/data/NIA48/training/calib/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "with open('/data/NIA50/50-2/data/NIA48/fine_data/S_Clip_02244_02/calib/Lidar_camera_calib/2-048_02244_LCC_CF.txt') as f:\n",
    "    camera_calib = f.readlines()\n",
    "# with open('/data/NIA48/S_Clip_03400_06/calib/Lidar_radar_calib/2-048_03400_LRC_RF.txt') as f:\n",
    "#     radar_calib = f.readlines()\n",
    "\n",
    "essential_matrix = np.asarray([[0, 1, 0],\n",
    "                               [0, 0, 1],\n",
    "                               [1, 0, 0]])\n",
    "# essential_matrix = E\n",
    "eulerangle = str2list(camera_calib[4]) # z, x, y\n",
    "# eulerangle = np.asarray(eulerangle) + np.asarray([-360*np.pi/180, -90*np.pi/180, -90*np.pi/180])\n",
    "X = R.from_euler('X', eulerangle[1]).as_matrix()\n",
    "Y = R.from_euler('Y', eulerangle[0]).as_matrix()\n",
    "Z = R.from_euler('Z', eulerangle[2]).as_matrix()\n",
    "rotation_matrix = Z @ Y @ X\n",
    "# rotation_matrix = R.from_euler('xyz', eulerangle).as_matrix()\n",
    "# e_rotation_matrix = np.matmul(rotation_matrix, essential_matrix)\n",
    "translation = np.asarray(str2list(camera_calib[6]))\n",
    "fpd = str2list(camera_calib[8])\n",
    "# resize_fpd = get_cropped_and_resized_intrinsic(fpd[0], fpd[1], fpd[2], fpd[3], 0, 0, 1920/735, 1200/575)\n",
    "# fpd = resize_fpd\n",
    "intrinsic = np.asarray([fpd[0], 0, fpd[2], 0,\n",
    "                        0, fpd[1], fpd[3], 0,\n",
    "                        0, 0, 1, 0]).reshape(3,4)\n",
    "distcoeffs = str2list(camera_calib[8])[4:]\n",
    "# new_intrinsic, _ = cv2.getOptimalNewCameraMatrix(cameraMatrix=intrinsic[:3, :3],\n",
    "#                                                 distCoeffs=np.asarray(distcoeffs),\n",
    "#                                                 imageSize=(1200, 1920),\n",
    "#                                                 alpha=1)\n",
    "# intrinsic = np.hstack([new_intrinsic, np.asarray([0, 0, 0]).reshape(3, 1)])\n",
    "extrinsic = np.hstack([rotation_matrix, np.asarray(translation).reshape(3, -1)])\n",
    "# extrinsic = np.hstack([e_rotation_matrix, np.asarray(translation).reshape(3, -1)])\n",
    "\n",
    "# projection_matrix = intrinsic\n",
    "# projection_matrix = np.matmul(intrinsic, extrinsic)\n",
    "# projection_matrix[2, 2] = 1\n",
    "# projection_matrix[:, 3] = 0\n",
    "\n",
    "# p2 = [projection_matrix[0, 0], 0, projection_matrix[0, 2], 0,\n",
    "#       0, projection_matrix[1, 1], projection_matrix[1, 2], 0,\n",
    "#       0, 0, 1, 0]\n",
    "# p2 = projection_matrix.reshape(-1).tolist()\n",
    "p2 = intrinsic.reshape(-1).tolist()\n",
    "\n",
    "R0_rect = np.eye(3).reshape(-1).tolist()\n",
    "# R0_rect = rotation_matrix.reshape(-1).tolist()\n",
    "Tr_velo_to_cam = extrinsic.reshape(-1).tolist()\n",
    "# Tr_velo_to_cam = np.zeros((12)).tolist()\n",
    "Tr_imu_to_velo = np.zeros((12)).tolist()\n",
    "\n",
    "calib_kitti =  ['P0: '+list2str(p2), \n",
    "                'P1: '+list2str(p2), \n",
    "                'P2: '+list2str(p2), \n",
    "                'P3: '+list2str(p2), \n",
    "                'R0_rect: '+list2str(R0_rect), \n",
    "                'Tr_velo_to_cam: '+list2str(Tr_velo_to_cam), \n",
    "                'Tr_imu_to_velo: '+list2str(Tr_imu_to_velo)]\n",
    "\n",
    "with open(path + 'test48.txt', 'w') as f:\n",
    "    f.write('\\n'.join(calib_kitti))\n",
    "\n",
    "# print(essential_matrix, '\\n')\n",
    "# print(rotation_matrix, '\\n')\n",
    "# print(extrinsic, '\\n')\n",
    "\n",
    "# with open('/data/hwang/datasets/kitti/training/calib/000038.txt') as f:\n",
    "#     calib = f.readlines()\n",
    "#     extrinsic_ = list(map(float, calib[5].replace('\\n', '').split(' ')[1:]))\n",
    "#     extrinsic_ = np.asarray(extrinsic_).reshape(3, 4)    \n",
    "#     R0_rect = list(map(float, calib[4].replace('\\n', '').split(' ')[1:]))\n",
    "#     R0_rect = np.asarray(R0_rect).reshape(3, 3)\n",
    "\n",
    "# print(extrinsic_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # label_2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/NIA50/50-2/data/NIA48/training/label_2/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "with open('/data/NIA50/50-2/data/NIA48/fine_data/S_Clip_02244_02/result/2-048_02244_FC_001.json', 'r') as f:\n",
    "    meta = json.load(f)\n",
    "    \n",
    "type_ = meta['annotation'][0]['category']\n",
    "truncation = 0.0\n",
    "occulsion = 0\n",
    "xyxy = meta['annotation'][0]['3d_box'][0]['2d_box']\n",
    "xyz = meta['annotation'][0]['3d_box'][0]['location']\n",
    "rotation_y = abs(meta['annotation'][0]['3d_box'][0]['rotation_y']) - 90 * np.pi/180\n",
    "\n",
    "xyz_re = np.matmul(extrinsic, np.asarray(xyz + [1]).reshape(4, 1)).reshape(-1).tolist()\n",
    "# xyz = np.matmul(e_rotation_matrix, np.asarray(xyz).reshape(3, 1)).reshape(-1).tolist()\n",
    "whl = meta['annotation'][0]['3d_box'][0]['dimension']\n",
    "hwlxyz = [whl[1], whl[0], whl[2]] + xyz_re\n",
    "\n",
    "alpha = cal_alpha_ori(xyz_re[0], xyz_re[2], rotation_y)\n",
    "\n",
    "xyxy = ' '.join(map(str, xyxy))\n",
    "hwlxyz = ' '.join(map(str, hwlxyz))\n",
    "\n",
    "label = list(map(str, [type_, truncation, occulsion, alpha, xyxy, hwlxyz, rotation_y]))\n",
    "\n",
    "with open(path+'test48.txt', 'w') as f:\n",
    "    f.write(' '.join(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = '02244'\n",
    "\n",
    "path = '/data/NIA50/50-2/data/NIA48/training/calib/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "with open(f'/data/NIA50/50-2/data/NIA48/fine_data/S_Clip_{num}_02/calib/Lidar_camera_calib/2-048_{num}_LCC_CF.txt') as f:\n",
    "    camera_calib = f.readlines()\n",
    "    \n",
    "eulerangle = str2list(camera_calib[4])\n",
    "eulerangle = np.asarray(eulerangle) + np.asarray([90*np.pi/180, -90*np.pi/180, -180*np.pi/180])\n",
    "eulerangle = np.asarray(eulerangle) + np.asarray([0*np.pi/180, 0*np.pi/180, 90*np.pi/180])\n",
    "# eulerangle[2] = eulerangle[2]*-1\n",
    "\n",
    "X = R.from_euler('X', eulerangle[1]).as_matrix()\n",
    "Y = R.from_euler('Y', eulerangle[0]).as_matrix()\n",
    "Z = R.from_euler('Z', eulerangle[2]).as_matrix()\n",
    "rotation_matrix = Z @ Y @ X\n",
    "\n",
    "# e_rotation_matrix = np.matmul(essential_matrix, rotation_matrix)\n",
    "# e_rotation_matrix = np.matmul(rotation_matrix, essential_matrix)\n",
    "translation = np.asarray(str2list(camera_calib[6]))\n",
    "# translation = translation = np.asarray(str2list(camera_calib[6])) + np.asarray([0, 0.6, 0.2])\n",
    "fpd = str2list(camera_calib[8])\n",
    "# resize_fpd = get_cropped_and_resized_intrinsic(fpd[0], fpd[1], fpd[2], fpd[3], 0, 0, 1920/745, 1200/575)\n",
    "# fpd = resize_fpd\n",
    "intrinsic = np.asarray([fpd[0], 0, fpd[2], 0,\n",
    "                        0, fpd[1], fpd[3], 0,\n",
    "                        0, 0, 1, 0]).reshape(3,4)\n",
    "# distortion = str2list(camera_calib[8])[4:]\n",
    "# new_intrinsic, _ = cv2.getOptimalNewCameraMatrix(cameraMatrix=intrinsic[:3, :3],\n",
    "#                                                 distCoeffs=np.asarray(distortion),\n",
    "#                                                 imageSize=(1200, 1920),\n",
    "#                                                 alpha=1)\n",
    "# intrinsic = np.hstack([new_intrinsic, np.asarray([0, 0, 0]).reshape(3, 1)])\n",
    "extrinsic = np.hstack([rotation_matrix, np.asarray(translation).reshape(3, -1)])\n",
    "\n",
    "p2 = intrinsic.reshape(-1).tolist()\n",
    "\n",
    "R0_rect = np.eye(3).reshape(-1).tolist()\n",
    "# R0_rect = rotation_matrix.reshape(-1).tolist()\n",
    "Tr_velo_to_cam = extrinsic.reshape(-1).tolist()\n",
    "# Tr_velo_to_cam = np.zeros((12)).tolist()\n",
    "Tr_imu_to_velo = np.zeros((12)).tolist()\n",
    "\n",
    "calib_kitti =  ['P0: '+list2str(p2), \n",
    "                'P1: '+list2str(p2), \n",
    "                'P2: '+list2str(p2), \n",
    "                'P3: '+list2str(p2), \n",
    "                'R0_rect: '+list2str(R0_rect), \n",
    "                'Tr_velo_to_cam: '+list2str(Tr_velo_to_cam), \n",
    "                'Tr_imu_to_velo: '+list2str(Tr_imu_to_velo)]\n",
    "\n",
    "with open(path + 'test48.txt', 'w') as f:\n",
    "    f.write('\\n'.join(calib_kitti))\n",
    "\n",
    "path = '/data/NIA50/50-2/data/NIA48/training/label_2/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "with open(f'/data/NIA50/50-2/data/NIA48/fine_data/S_Clip_{num}_02/result/2-048_{num}_FC_001.json', 'r') as f:\n",
    "    meta = json.load(f)\n",
    "    \n",
    "type_ = meta['annotation'][0]['category']\n",
    "truncation = 0.0\n",
    "occulsion = 0\n",
    "xyxy = meta['annotation'][0]['3d_box'][0]['2d_box']\n",
    "xyz = meta['annotation'][0]['3d_box'][0]['location']\n",
    "rotation_y = np.abs(meta['annotation'][0]['3d_box'][0]['rotation_y']) - 90 * np.pi/180 # radian\n",
    "# rotation_y = meta['annotation'][0]['3d_box'][0]['rotation_y']\n",
    "\n",
    "\n",
    "xyz_re = np.matmul(extrinsic, np.asarray(xyz + [1]).reshape(4, 1)).reshape(-1).tolist()\n",
    "# xyz = np.matmul(e_rotation_matrix, np.asarray(xyz).reshape(3, 1)).reshape(-1).tolist()\n",
    "whl = meta['annotation'][0]['3d_box'][0]['dimension']\n",
    "hwlxyz = [whl[1], whl[0], whl[2]] + xyz_re\n",
    "# hwlxyz = [whl[1], whl[0], whl[2]] + [xyz_re[2], xyz_re[1], xyz_re[0]]\n",
    "\n",
    "alpha = cal_alpha_ori(xyz_re[0], xyz_re[2], rotation_y)\n",
    "\n",
    "xyxy = ' '.join(map(str, xyxy))\n",
    "hwlxyz = ' '.join(map(str, hwlxyz))\n",
    "\n",
    "label = list(map(str, [type_, truncation, occulsion, alpha, xyxy, hwlxyz, rotation_y]))\n",
    "\n",
    "with open(path+'test48.txt', 'w') as f:\n",
    "    f.write(' '.join(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eulerangle = str2list(camera_calib[4])\n",
    "# eulerangle = np.asarray(eulerangle) + np.asarray([-180*np.pi/180, 90*np.pi/180, -90*np.pi/180])\n",
    "R.from_euler('XYZ', eulerangle).as_matrix().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eulerangle = str2list(camera_calib[4])\n",
    "# eulerangle = np.asarray(eulerangle) + np.asarray([-180*np.pi/180, 90*np.pi/180, -90*np.pi/180])\n",
    "R.from_euler('xyz', eulerangle).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(Tr_velo, dtype=float).reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '/data/NIA50/50-2/data/NIA48/training/calib/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "with open('/data/NIA50/50-2/data/NIA48/fine_data/S_Clip_02244_02/calib/Lidar_camera_calib/2-048_02244_LCC_CF.txt') as f:\n",
    "    camera_calib = f.readlines()\n",
    "# with open('/data/NIA48/S_Clip_03400_06/calib/Lidar_radar_calib/2-048_03400_LRC_RF.txt') as f:\n",
    "#     radar_calib = f.readlines()\n",
    "\n",
    "# essential_matrix = np.asarray([[0, 1, 0],\n",
    "#                                [0, 0, 1],\n",
    "#                                [1, 0, 0]])\n",
    "# essential_matrix = E\n",
    "eulerangle = str2list(camera_calib[4])\n",
    "eulerangle = np.asarray(eulerangle) + np.asarray([360*np.pi/180, 90*np.pi/180, 90*np.pi/180])\n",
    "rotation_matrix = R.from_euler('xyz', eulerangle).as_matrix()\n",
    "# e_rotation_matrix = np.matmul(essential_matrix, rotation_matrix)\n",
    "# e_rotation_matrix = np.matmul(rotation_matrix, essential_matrix)\n",
    "translation = np.asarray(str2list(camera_calib[6]))\n",
    "fpd = str2list(camera_calib[8])\n",
    "intrinsic = np.asarray([fpd[0], 0, fpd[2], 0,\n",
    "                        0, fpd[1], fpd[3], 0,\n",
    "                        0, 0, 1, 0]).reshape(3,4)\n",
    "distortion = str2list(camera_calib[8])[4:]\n",
    "new_intrinsic, _ = cv2.getOptimalNewCameraMatrix(cameraMatrix=intrinsic[:3, :3],\n",
    "                                                distCoeffs=np.asarray(distortion),\n",
    "                                                imageSize=(1200, 1920),\n",
    "                                                alpha=0)\n",
    "intrinsic = np.hstack([new_intrinsic, np.asarray([0, 0, 0]).reshape(3, 1)])\n",
    "extrinsic = np.hstack([rotation_matrix, np.asarray(translation).reshape(3, -1)])\n",
    "# extrinsic = np.hstack([e_rotation_matrix, np.asarray(translation).reshape(3, -1)])\n",
    "\n",
    "# projection_matrix = intrinsic\n",
    "# projection_matrix = np.matmul(intrinsic, extrinsic)\n",
    "# projection_matrix[2, 2] = 1\n",
    "# projection_matrix[:, 3] = 0\n",
    "\n",
    "# p2 = [projection_matrix[0, 0], 0, projection_matrix[0, 2], 0,\n",
    "#       0, projection_matrix[1, 1], projection_matrix[1, 2], 0,\n",
    "#       0, 0, 1, 0]\n",
    "# p2 = projection_matrix.reshape(-1).tolist()\n",
    "p2 = intrinsic.reshape(-1).tolist()\n",
    "\n",
    "R0_rect = np.eye(3).reshape(-1).tolist()\n",
    "# R0_rect = rotation_matrix.reshape(-1).tolist()\n",
    "Tr_velo_to_cam = extrinsic.reshape(-1).tolist()\n",
    "# Tr_velo_to_cam = np.zeros((12)).tolist()\n",
    "Tr_imu_to_velo = np.zeros((12)).tolist()\n",
    "\n",
    "calib_kitti =  ['P0: '+list2str(p2), \n",
    "                'P1: '+list2str(p2), \n",
    "                'P2: '+list2str(p2), \n",
    "                'P3: '+list2str(p2), \n",
    "                'R0_rect: '+list2str(R0_rect), \n",
    "                'Tr_velo_to_cam: '+list2str(Tr_velo_to_cam), \n",
    "                'Tr_imu_to_velo: '+list2str(Tr_imu_to_velo)]\n",
    "\n",
    "with open(path + 'test48.txt', 'w') as f:\n",
    "    f.write('\\n'.join(calib_kitti))\n",
    "\n",
    "# print(essential_matrix, '\\n')\n",
    "# print(rotation_matrix, '\\n')\n",
    "# print(extrinsic, '\\n')\n",
    "\n",
    "# with open('/data/hwang/datasets/kitti/training/calib/000038.txt') as f:\n",
    "#     calib = f.readlines()\n",
    "#     extrinsic_ = list(map(float, calib[5].replace('\\n', '').split(' ')[1:]))\n",
    "#     extrinsic_ = np.asarray(extrinsic_).reshape(3, 4)    \n",
    "#     R0_rect = list(map(float, calib[4].replace('\\n', '').split(' ')[1:]))\n",
    "#     R0_rect = np.asarray(R0_rect).reshape(3, 3)\n",
    "\n",
    "# print(extrinsic_)\n",
    "\n",
    "path = '/data/NIA50/50-2/data/NIA48/training/label_2/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "with open('/data/NIA50/50-2/data/NIA48/fine_data/S_Clip_02244_02/result/2-048_02244_FC_001.json', 'r') as f:\n",
    "    meta = json.load(f)\n",
    "    \n",
    "type_ = meta['annotation'][0]['category']\n",
    "truncation = 0.0\n",
    "occulsion = 0\n",
    "xyxy = meta['annotation'][0]['3d_box'][0]['2d_box']\n",
    "xyz = meta['annotation'][0]['3d_box'][0]['location']\n",
    "rotation_y = abs(meta['annotation'][0]['3d_box'][0]['rotation_y']) - 90 * np.pi/180\n",
    "\n",
    "xyz_re = np.matmul(extrinsic, np.asarray(xyz + [1]).reshape(4, 1)).reshape(-1).tolist()\n",
    "# xyz = np.matmul(e_rotation_matrix, np.asarray(xyz).reshape(3, 1)).reshape(-1).tolist()\n",
    "whl = meta['annotation'][0]['3d_box'][0]['dimension']\n",
    "hwlxyz = [whl[1], whl[0], whl[2]] + xyz_re\n",
    "\n",
    "alpha = cal_alpha_ori(xyz_re[0], xyz_re[2], rotation_y)\n",
    "\n",
    "xyxy = ' '.join(map(str, xyxy))\n",
    "hwlxyz = ' '.join(map(str, hwlxyz))\n",
    "\n",
    "label = list(map(str, [type_, truncation, occulsion, alpha, xyxy, hwlxyz, rotation_y]))\n",
    "\n",
    "with open(path+'test48.txt', 'w') as f:\n",
    "    f.write(' '.join(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # NIA50\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # PointRCNN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # velodyne\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/velodyne', exist_ok=True)\n",
    "\n",
    "path = '/data/NIA50/50-2/data/NIA50_samples/'\n",
    "clips = sorted(os.listdir(path))\n",
    "for clip in clips[1:2]:\n",
    "    # frames = sorted(os.listdir(f'/data/NIA50/50-2/data/NIA50_samples/{clip}/lidar'))    \n",
    "    pcd_files = sorted(glob.glob(path+f'{clip}/lidar/*.pcd'))\n",
    "    for pcd_file in pcd_files:\n",
    "        frame = pcd_file[-8:-4]\n",
    "        pcd = o3d.t.io.read_point_cloud(pcd_file)\n",
    "        positions = pcd.point.positions.numpy()\n",
    "        intensity = pcd.point.intensity.numpy()\n",
    "        \n",
    "        pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "        pcd_bytes = pcd.tobytes()\n",
    "        \n",
    "        with open(f'/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/velodyne/{clip}_{frame}.bin', 'wb') as f:\n",
    "            f.write(pcd_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/velodyne/{clip}_{frame}.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # calib\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/calib', exist_ok=True)\n",
    "\n",
    "\n",
    "path = '/data/NIA50/50-2/data/NIA50_samples/'\n",
    "\n",
    "clips = sorted(os.listdir(path))\n",
    "for clip in clips[1:2]:\n",
    "    frames = sorted(os.listdir(path + clip + '/lidar'))\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame = frame[:4]\n",
    "        with open(path+f'{clip}/calib_1.txt') as f:\n",
    "            calib = f.readlines()\n",
    "\n",
    "        # essential_matrix = np.asarray([[0, 1, 0],\n",
    "        #                                [0, 0, 1],\n",
    "        #                                [1, 0, 0]])\n",
    "        # essential_matrix = np.eye(3)\n",
    "        eulerangle = str2list(calib[4])\n",
    "        X = R.from_euler('X', eulerangle[1]).as_matrix()\n",
    "        Y = R.from_euler('Y', eulerangle[0]).as_matrix()\n",
    "        Z = R.from_euler('Z', eulerangle[2]).as_matrix()\n",
    "        # X = R.from_euler('X', eulerangle[2]).as_matrix()\n",
    "        # Y = R.from_euler('Y', eulerangle[1]).as_matrix()\n",
    "        # Z = R.from_euler('Z', eulerangle[0]).as_matrix()\n",
    "        rotation_matrix = Z @ Y @ X\n",
    "        # rotation_matrix = R.from_euler('xyz', eulerangle).as_matrix()\n",
    "        # e_rotation_matrix = np.matmul(essential_matrix, rotation_matrix)\n",
    "        # e_rotation_matrix = np.matmul(rotation_matrix, essential_matrix)\n",
    "        translation = str2list(calib[6])\n",
    "        fpd = str2list(calib[8])\n",
    "        intrinsic = np.asarray([fpd[0], 0, fpd[2], 0,\n",
    "                                0, fpd[1], fpd[3], 0,\n",
    "                                0, 0, 1, 0]).reshape(3,4)\n",
    "        extrinsic = np.hstack([rotation_matrix, np.asarray(translation).reshape(3, -1)])\n",
    "\n",
    "\n",
    "        p2 = intrinsic.reshape(-1).tolist()\n",
    "        R0_rect = np.eye(3).reshape(-1).tolist()\n",
    "        Tr_velo_to_cam = extrinsic.reshape(-1).tolist()\n",
    "        Tr_imu_to_velo = np.zeros((12)).tolist()\n",
    "\n",
    "        calib_kitti =  ['P0: '+list2str(p2), \n",
    "                        'P1: '+list2str(p2), \n",
    "                        'P2: '+list2str(p2), \n",
    "                        'P3: '+list2str(p2), \n",
    "                        'R0_rect: '+list2str(R0_rect), \n",
    "                        'Tr_velo_to_cam: '+list2str(Tr_velo_to_cam), \n",
    "                        'Tr_imu_to_velo: '+list2str(Tr_imu_to_velo)]\n",
    "\n",
    "        with open(f'/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/calib/{clip}_{frame}.txt', 'w') as f:\n",
    "            f.write('\\n'.join(calib_kitti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_json = {\n",
    "    \"extrinsic\": np.asarray(np.vstack([extrinsic, np.asarray([0, 0, 0, 1])]), dtype=np.float32).flatten().tolist(),\n",
    "    \"intrinsic\": np.asarray(p2, dtype=np.float32).reshape(-1, 4)[:3, :3].flatten().tolist()\n",
    "}\n",
    "json_object = json.dumps(calib_json, indent = 4) \n",
    "# Writing to sample.json \n",
    "with open('/data/NIA50/SUSTechPOINTS_2-050/data/Suwon_A_0000/calib/camera/front.json', \"w\") as outfile: \n",
    "    outfile.write(json_object) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # label_2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 구하는 공식\n",
    "import math\n",
    "\n",
    "def normalizeAngle(angle):\n",
    "    result = angle % (2*math.pi)\n",
    "    if result < -math.pi:\n",
    "        result += 2*math.pi\n",
    "    elif result > math.pi:\n",
    "        result -= 2*math.pi\n",
    "    return result\n",
    "\n",
    "def cal_alpha_ori(x, z, ry):  \n",
    "    angle = ry\n",
    "    angle -= -math.atan2(z, x) -1.5*math.pi \n",
    "    alpha = normalizeAngle(angle)\n",
    "    return alpha # -1.818032754845337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/label_2', exist_ok=True)\n",
    "\n",
    "path = '/data/NIA50/50-2/data/NIA50_samples/'\n",
    "clips = sorted(os.listdir(path))\n",
    "for clip in clips[1:2]:\n",
    "    labels = sorted(glob.glob(path+f'{clip}/label/*.json'))\n",
    "    \n",
    "    for label in labels:\n",
    "        frame = label[-9:-5]\n",
    "        with open(label, 'r') as f:\n",
    "            label_js = json.load(f)\n",
    "            \n",
    "        for i in np.arange(len(label_js)):\n",
    "            type_ = label_js[i]['obj_type']\n",
    "            \n",
    "            truncation = 0.0\n",
    "            occulsion = 0\n",
    "            \n",
    "            xyxy = [0, 0, 0, 0]\n",
    "            xyxy = ' '.join(map(str, xyxy))\n",
    "            \n",
    "            scale = label_js[i]['psr']['scale']\n",
    "            hwl = [scale['z'], scale['y'], scale['x']]\n",
    "            \n",
    "            position = label_js[i]['psr']['position']\n",
    "            xyz = [position['x'], position['y'], position['z']]            \n",
    "            xyz_re = np.matmul(extrinsic, np.asarray(xyz + [1]).reshape(4, 1)).reshape(-1).tolist()\n",
    "            \n",
    "            hwlxyz = hwl + xyz_re\n",
    "            hwlxyz = ' '.join(map(str, hwlxyz))\n",
    "            rotation_y = label_js[i]['psr']['rotation']['z']\n",
    "            \n",
    "            alpha = cal_alpha_ori(xyz_re[0], xyz_re[2], rotation_y)\n",
    "            \n",
    "            label_2 = list(map(str, [type_, truncation, occulsion, alpha, xyxy, hwlxyz, rotation_y]))\n",
    "\n",
    "            # 파일 삭제   \n",
    "            # if os.path.isfile(f'/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/label_2/{clip}_{frame}.txt'):\n",
    "            #     os.remove(f'/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/label_2/{clip}_{frame}.txt')\n",
    "                \n",
    "            with open(f'/data/NIA50/50-2/data/mot_nia50/pointrcnn/training/label_2/{clip}_{frame}.txt', 'a') as f:\n",
    "                f.write(' '.join(label_2)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # PV-RCNN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # points\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = sorted(glob.glob('/data/NIA50/50-2/data/NIA50_real/*/lidar/*.pcd'))\n",
    "save_path = '/data/NIA50/50-2/data/mot_nia50/pvrcnn/points/'\n",
    "\n",
    "for point in points:\n",
    "    clip = re.search('Suwon_[A-Z_0-9]+', point).group()\n",
    "    frame = re.search('[0-9]+.pcd', point).group().replace('.pcd', '')\n",
    "    \n",
    "    pcd = o3d.t.io.read_point_cloud(point)\n",
    "    positions = pcd.point.positions.numpy()\n",
    "    intensity = pcd.point.intensity.numpy()\n",
    "    pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "\n",
    "    npy = np.save(save_path+f'/{clip}_{frame}.npy', pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # labels\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨링 에러 : Suwon_A_2210261635_0001 0001 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0001 0005 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0005 0006 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0026 0000 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0047 0001 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0047 0003 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0047 0004 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0047 0005 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0057 0008 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0087 0003 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0024 0009 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0030 0000 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0038 0009 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0049 0000 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0056 0000 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0072 0001 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0076 0008 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0134 0002 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0158 0004 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0171 0001 0\n",
      "라벨링 에러 : Suwon_B_2210271119_0085 0001 0\n",
      "json 에러 : Suwon_B_2210271119_0138 0006\n",
      "json 에러 : Suwon_B_2210271119_0138 0007\n",
      "json 에러 : Suwon_B_2210271119_0138 0008\n",
      "json 에러 : Suwon_B_2210271119_0138 0009\n",
      "라벨링 에러 : Suwon_B_2210271119_0193 0000 0\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(glob.glob('/data/NIA50/50-2/data/NIA50_real/*/label/*.json'))\n",
    "save_path = '/data/NIA50/50-2/data/mot_nia50/pvrcnn/labels/'\n",
    "\n",
    "class_list = []\n",
    "rename = {'Adult': 'PEDESTRIAN', \n",
    "          'Bus': 'CAR',\n",
    "          'Car': 'CAR',\n",
    "          'Kid': 'PEDESTRIAN',\n",
    "          'Kickboard': 'MOTORCYCLE',\n",
    "          'Large_Truck': 'CAR',\n",
    "          'Light_Car': 'CAR',\n",
    "          'Medium_Truck': 'CAR',\n",
    "          'Mini_Bus': 'CAR',\n",
    "          'Motorcycle': 'MOTORCYCLE',\n",
    "          'Pedestrian': 'PEDESTRIAN',\n",
    "          'SUV': 'CAR',\n",
    "          'Small_Car': 'CAR',\n",
    "          'Small_Truck': 'CAR',\n",
    "          'Special_Vehicle': 'CAR',\n",
    "          'Two_Wheeler': 'MOTORCYCLE',\n",
    "          'Van': 'CAR'}\n",
    "\n",
    "for label in labels:\n",
    "    try:\n",
    "        clip = re.search('Suwon_[A-Z_0-9]+', label).group()\n",
    "        frame = re.search('[0-9]+.json', label).group().replace('.json', '')\n",
    "        \n",
    "        with open(label, 'r') as f:\n",
    "            label = json.load(f)\n",
    "        \n",
    "        label_txt = []\n",
    "        for i in np.arange(len(label)):\n",
    "            try:\n",
    "            # print(clip)\n",
    "            # print(frame)\n",
    "                xyz = list(label[i]['psr']['position'].values())\n",
    "                lwh = list(label[i]['psr']['scale'].values())\n",
    "                rotation_y = [label[i]['psr']['rotation']['z']]\n",
    "                class_ = label[i]['obj_type']\n",
    "                rename_class = [rename[class_]]\n",
    "                # if class_ == 'Special_Vehicle':\n",
    "                #     print(clip, frame)\n",
    "                # class_list.append(class_)\n",
    "                class_list.append(rename_class[0])\n",
    "                label_format = ' '.join(map(str, xyz + lwh + rotation_y + rename_class))\n",
    "                label_txt.append(label_format)\n",
    "            except KeyError:\n",
    "                print('라벨링 에러 :', clip, frame, class_)\n",
    "\n",
    "        with open(save_path+f'/{clip}_{frame}.txt', 'w') as f:\n",
    "            f.write('\\n'.join(label_txt))\n",
    "        \n",
    "    except ValueError:\n",
    "        print('json 에러 :', clip, frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41890"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # ImageSets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨링 에러 : Suwon_A_2210261635_0001 0001 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0001 0005 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0005 0006 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0026 0000 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0047 0001 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0047 0003 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0047 0004 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0047 0005 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0057 0008 0\n",
      "라벨링 에러 : Suwon_A_2210261635_0087 0003 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0024 0009 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0030 0000 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0038 0009 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0049 0000 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0056 0000 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0072 0001 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0076 0008 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0134 0002 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0158 0004 0\n",
      "라벨링 에러 : Suwon_A_2210271119_0171 0001 0\n",
      "라벨링 에러 : Suwon_B_2210271119_0085 0001 0\n",
      "json 에러 : Suwon_B_2210271119_0138 0006\n",
      "json 에러 : Suwon_B_2210271119_0138 0007\n",
      "json 에러 : Suwon_B_2210271119_0138 0008\n",
      "json 에러 : Suwon_B_2210271119_0138 0009\n",
      "라벨링 에러 : Suwon_B_2210271119_0193 0000 0\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(glob.glob('/data/NIA50/50-2/data/NIA50_real/*/label/*.json'))\n",
    "# save_path = '/data/NIA50/50-2/data/mot_nia50/pvrcnn/labels/'\n",
    "\n",
    "df = pd.DataFrame(columns = ['clip', 'CAR', 'PEDESTRIAN', 'MOTORCYCLE'])\n",
    "rename = {'Adult': 'PEDESTRIAN', \n",
    "          'Bus': 'CAR',\n",
    "          'Car': 'CAR',\n",
    "          'Kid': 'PEDESTRIAN',\n",
    "          'Kickboard': 'MOTORCYCLE',\n",
    "          'Large_Truck': 'CAR',\n",
    "          'Light_Car': 'CAR',\n",
    "          'Medium_Truck': 'CAR',\n",
    "          'Mini_Bus': 'CAR',\n",
    "          'Motorcycle': 'MOTORCYCLE',\n",
    "          'Pedestrian': 'PEDESTRIAN',\n",
    "          'SUV': 'CAR',\n",
    "          'Small_Car': 'CAR',\n",
    "          'Small_Truck': 'CAR',\n",
    "          'Special_Vehicle': 'CAR',\n",
    "          'Two_Wheeler': 'MOTORCYCLE',\n",
    "          'Van': 'CAR'}\n",
    "\n",
    "error_clips = []\n",
    "for idx, label in enumerate(labels):\n",
    "    try:\n",
    "        clip = re.search('Suwon_[A-Z_0-9]+', label).group()\n",
    "        frame = re.search('[0-9]+.json', label).group().replace('.json', '')\n",
    "        \n",
    "        with open(label, 'r') as f:\n",
    "            label = json.load(f)\n",
    "        \n",
    "        class_list = []\n",
    "        # label_txt = []\n",
    "        for i in np.arange(len(label)):\n",
    "            try:\n",
    "                class_ = label[i]['obj_type']\n",
    "                rename_class = [rename[class_]]\n",
    "                class_list.append(rename_class[0])\n",
    "            except KeyError:\n",
    "                print('라벨링 에러 :', clip, frame, class_)\n",
    "        \n",
    "        cnt = Counter(class_list)\n",
    "        df.loc[idx] = [clip, cnt['CAR'], cnt['PEDESTRIAN'], cnt['MOTORCYCLE']]\n",
    "        # with open(save_path+f'/{clip}_{frame}.txt', 'w') as f:\n",
    "        #     f.write('\\n'.join(label_txt))\n",
    "        \n",
    "    except ValueError:\n",
    "        print('json 에러 :', clip, frame)\n",
    "        error_clips.append(clip)\n",
    "        \n",
    "df_ = df.groupby(['clip']).sum().reset_index()\n",
    "\n",
    "error_clip_idx = []\n",
    "for error_clip in list(set(error_clips)):\n",
    "    idx = df_.loc[df_['clip'] == error_clip].index.values\n",
    "    error_clip_idx.append(int(idx))\n",
    "\n",
    "df_ = df_.drop(error_clip_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR</th>\n",
       "      <th>PEDESTRIAN</th>\n",
       "      <th>MOTORCYCLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>86.010288</td>\n",
       "      <td>19.320988</td>\n",
       "      <td>2.876543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>54.994301</td>\n",
       "      <td>33.444335</td>\n",
       "      <td>5.888061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>122.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>262.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CAR  PEDESTRIAN  MOTORCYCLE\n",
       "count  486.000000  486.000000  486.000000\n",
       "mean    86.010288   19.320988    2.876543\n",
       "std     54.994301   33.444335    5.888061\n",
       "min      0.000000    0.000000    0.000000\n",
       "25%     42.000000    0.000000    0.000000\n",
       "50%     77.000000    0.000000    0.000000\n",
       "75%    122.000000   30.000000    2.000000\n",
       "max    262.000000  199.000000   32.000000"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388, 98)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip1 = list(df_.loc[(df_['PEDESTRIAN'] >= 1) & (df_['MOTORCYCLE'] >= 1), 'clip'])\n",
    "clip2 = list(df_.loc[(df_['PEDESTRIAN'] < 1) | (df_['MOTORCYCLE'] < 1), 'clip'])\n",
    "\n",
    "train1, val1 = train_test_split(clip1, test_size=0.2, random_state=0)\n",
    "train2, val2 = train_test_split(clip2, test_size=0.2, random_state=0)\n",
    "\n",
    "train = sorted(train1 + train2); val = sorted(val1 + val2)\n",
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/data/NIA50/50-2/data/mot_nia50/pvrcnn/ImageSets/'\n",
    "\n",
    "frames = [str(i).zfill(4) for i in np.arange(0, 10)]\n",
    "\n",
    "train_list = []\n",
    "for clip in train:\n",
    "    for frame in frames:\n",
    "        train_file = clip + f'_{frame}'\n",
    "        train_list.append(train_file)\n",
    "\n",
    "val_list = []\n",
    "for clip in val:\n",
    "    for frame in frames:\n",
    "        val_file = clip + f'_{frame}'\n",
    "        val_list.append(val_file)\n",
    "        \n",
    "\n",
    "with open(save_path + 'train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(train_list))           \n",
    "    \n",
    "with open(save_path + 'val.txt', 'w') as f:\n",
    "    f.write('\\n'.join(val_list))           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('spiner310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746d95b724613cc31ae9ea1c95fce8e51ec3ee7393c1b2a647745f061ae2ccda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
