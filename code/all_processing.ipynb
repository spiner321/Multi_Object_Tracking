{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 모듈 및 함수\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import open3d as o3d\n",
    "import pickle as pkl\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "import glob\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def xyxy2xywhn(x, w=1920, h=1200, clip=False, eps=0.0):\n",
    "    # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right\n",
    "    if clip:\n",
    "        clip_boxes(x, (h - eps, w - eps))  # warning: inplace clip\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    y = np.copy(x)\n",
    "    y[:, 0] = ((x[:, 0] + x[:, 2]) / 2) / w  # x center\n",
    "    y[:, 1] = ((x[:, 1] + x[:, 3]) / 2) / h  # y center\n",
    "    y[:, 2] = (x[:, 2] - x[:, 0]) / w  # width\n",
    "    y[:, 3] = (x[:, 3] - x[:, 1]) / h  # height\n",
    "    y = list(y.reshape(-1))\n",
    "    return y\n",
    "\n",
    "def convert_x1y1x2y2_to_tlwh(bbox):\n",
    "    '''\n",
    "    :param bbox: x1 y1 x2 y2\n",
    "    :return: tlwh: top_left x   top_left y    width   height\n",
    "    '''\n",
    "    w = bbox[2] - bbox[0]\n",
    "    h = bbox[3] - bbox[1]\n",
    "    return np.array(([bbox[0], bbox[1], w, h]))\n",
    "\n",
    "# rotation matrix\n",
    "def roty(t, Rx=90/180*np.pi):\n",
    "    ''' Rotation about the y-axis. '''\n",
    "    c = np.cos(t)\n",
    "    s = np.sin(t)\n",
    "    \n",
    "    X = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(Rx), -np.sin(Rx)],\n",
    "                    [0, np.sin(Rx), np.cos(Rx)]])\n",
    "\n",
    "    Z = np.array([[c, -s, 0],\n",
    "                    [s, c, 0],\n",
    "                    [0, 0, 1]])\n",
    "    \n",
    "    return np.matmul(Z, X)\n",
    "\n",
    "def xyz2xyxy(x, y, z, l, w, h, rot_y, extrinsic, intrinsic):\n",
    "    R = roty(rot_y)\n",
    "   \n",
    "    x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2];\n",
    "    y_corners = [h / 2, h / 2, h / 2, h / 2, -h / 2, -h / 2, -h / 2, -h / 2];\n",
    "    z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2];\n",
    "    \n",
    "    corners_3d = np.dot(R, np.vstack([x_corners, y_corners, z_corners]))\n",
    "    corners_3d[0, :] = corners_3d[0, :] + x  # x\n",
    "    corners_3d[1, :] = corners_3d[1, :] + y  # y\n",
    "    corners_3d[2, :] = corners_3d[2, :] + z  # z\n",
    "    corners_3d = np.vstack([corners_3d, [1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "    \n",
    "    point2d = np.matmul(intrinsic, np.matmul(extrinsic, corners_3d))\n",
    "    pointx = np.around(point2d/point2d[2])[0]\n",
    "    pointy = np.around(point2d/point2d[2])[1]\n",
    "\n",
    "    return min(pointx), min(pointy), max(pointx), max(pointy)\n",
    "\n",
    "# 문자열 숫자리스트로 바꾸는 함수\n",
    "def str2list(txt):\n",
    "    txt = txt.replace('\\n', '').split(',')\n",
    "    txt = list(map(float, txt))\n",
    "    \n",
    "    return txt\n",
    "\n",
    "# 리스트를 문자열로 바꾸는 함수\n",
    "def list2str(list):\n",
    "    list = ' '.join(map(str, list))\n",
    "    \n",
    "    return list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 데이터 프레임 만들기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58160/58160 [17:41<00:00, 54.80it/s] \n"
     ]
    }
   ],
   "source": [
    "src = '/data/NIA50/50-2/data/nia50_final/raw'\n",
    "dst = '/data/NIA50/50-2/data/nia50_final'\n",
    "\n",
    "\n",
    "# Z축 이동을 위해서 calib와 매칭하여 이동범위 지정\n",
    "calib_ls = []\n",
    "# scenes = []\n",
    "calibs = sorted(glob.glob(f'{src}/*/calib/camera/camera_0.json'))\n",
    "for calib in calibs:\n",
    "    scene = re.findall('[a-zA-Z0-9_]+', calib)[-5]\n",
    "    with open(calib, 'r') as f:\n",
    "        calib = json.load(f)\n",
    "    if calib['extrinsic'] not in calib_ls:\n",
    "        calib_ls.append(calib['extrinsic'])\n",
    "        # scenes.append(scene)    \n",
    "calib_typ = {'typ1': {'calib': calib_ls[0], 'mov_zpoint': 14},\n",
    "             'typ2': {'calib': calib_ls[1], 'mov_zpoint': 13},\n",
    "             'typ3': {'calib': calib_ls[2], 'mov_zpoint': 0},\n",
    "             'typ4': {'calib': calib_ls[3], 'mov_zpoint': -20}}\n",
    "\n",
    "\n",
    "# 라벨데이터로 데이터프레임 생성\n",
    "dp_ls = []\n",
    "labels = sorted(glob.glob(f'{src}/*/label/*.json'))\n",
    "for j, label in enumerate(tqdm(labels)):\n",
    "    scene = re.findall('\\w+', label)[-4]\n",
    "    frame = re.findall('\\w+', label)[-2]\n",
    "\n",
    "    # calib값 조정\n",
    "    with open(f'{src}/{scene}/calib/camera/camera_0.json', 'r') as f:\n",
    "        calib = json.load(f)\n",
    "\n",
    "    extrinsic = np.asarray(calib['extrinsic']).reshape(4, 4)\n",
    "    intrinsic = np.zeros([3, 4])\n",
    "    intrinsic[:3, :3] = np.asarray(calib['intrinsic']).reshape(3, 3)\n",
    "    \n",
    "    for typ in ['typ1', 'typ2', 'typ3', 'typ4']:\n",
    "        if calib['extrinsic'] == calib_typ[typ]['calib']:\n",
    "            # extrinsic = np.asarray(calib['extrinsic']).reshape(4, 4)\n",
    "            extrinsic[:3, 3] -= extrinsic[:3, 2] * calib_typ[typ]['mov_zpoint']   \n",
    "\n",
    "    # 컬럼 구성\n",
    "    globals()[f'dp{j}'] = pd.DataFrame()\n",
    "    with open(label, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    for i in range(len(json_data)):\n",
    "        try:\n",
    "            id_ = json_data[i]['obj_id']\n",
    "            class_ = json_data[i]['obj_type']\n",
    "            psr = json_data[i]['psr']\n",
    "            point_x, point_y, point_z = psr['position']['x'], psr['position']['y'], psr['position']['z']\n",
    "            # z값 범위를 줄이기 위해 조정\n",
    "            for typ in ['typ1', 'typ2', 'typ3', 'typ4']:\n",
    "                if calib['extrinsic'] == calib_typ[typ]['calib']:\n",
    "                    mov_point_z = calib_typ[typ]['mov_zpoint']\n",
    "                    point_z += mov_point_z\n",
    "            l, w, h = psr['scale']['x'], psr['scale']['y'], psr['scale']['z']\n",
    "            rot_y = psr['rotation']['z']\n",
    "            min_x, min_y, max_x, max_y = xyz2xyxy(point_x, point_y, point_z, l, w, h, rot_y, extrinsic, intrinsic)\n",
    "\n",
    "            data = [\n",
    "                id_, class_, \n",
    "                min_x, min_y, max_x, max_y,\n",
    "                point_x, point_y, point_z,\n",
    "                l, w, h,\n",
    "                rot_y,\n",
    "                intrinsic.flatten().tolist(), extrinsic.flatten().tolist(), mov_point_z,\n",
    "                scene, frame\n",
    "                ]\n",
    "            \n",
    "            columns = [\n",
    "                'id', 'class',\n",
    "                'min_x', 'min_y', 'max_x', 'max_y',\n",
    "                'point_x', 'point_y', 'point_z',\n",
    "                'l', 'w', 'h',\n",
    "                'rot_y',\n",
    "                'intrinsic', 'extrinsic', 'mov_point_z',\n",
    "                'scene', 'frame'\n",
    "                ]\n",
    "\n",
    "            frame_data = pd.DataFrame(data=[data], columns=columns)\n",
    "            globals()[f'dp{j}'] = pd.concat([globals()[f'dp{j}'], frame_data], axis=0)\n",
    "        except:\n",
    "            continue\n",
    "    dp_ls.append(globals()[f'dp{j}'])\n",
    "    \n",
    "dp = pd.concat(dp_ls).reset_index(drop=True)\n",
    "\n",
    "# dp.loc[dp['min_x'] < 0, 'min_x'] = 0\n",
    "# dp.loc[dp['min_x'] > 1920, 'min_x'] = 1920\n",
    "# dp.loc[dp['max_x'] < 0, 'max_x'] = 0\n",
    "# dp.loc[dp['max_x'] > 1920, 'max_x'] = 1920\n",
    "# dp.loc[dp['min_y'] < 0, 'min_y'] = 0\n",
    "# dp.loc[dp['min_y'] > 1200, 'min_y'] = 1200\n",
    "# dp.loc[dp['max_y'] < 0, 'max_y'] = 0\n",
    "# dp.loc[dp['max_y'] > 1200, 'max_y'] = 1200\n",
    "dp['id'] = dp['id'].apply(pd.to_numeric, errors='coerce')\n",
    "dp = dp.dropna(axis=0)\n",
    "# drop_index = dp.loc[(dp['class']==0)| (dp['class']=='Unknown') | (dp['id'].isnull()) | \n",
    "#                     (dp['min_x']-dp['max_x']==0) | (dp['min_y']-dp['max_y']==0) |\n",
    "#                     (dp['point_y']>0) | (dp['point_y']<-50) | (dp['point_x']<-50) | (dp['point_x']>50)].index\n",
    "# dp = dp.drop(drop_index).reset_index(drop=True)\n",
    "dp['id'] = dp['id'].astype(int)\n",
    "dp.to_csv(f'{dst}/data_info.csv')\n",
    "# dp = pd.read_csv('/data/NIA50/50-2/data/nia50_final/data_info.csv', index_col=0, dtype={'frame':object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 체크\n",
    "no_label = []\n",
    "src = '/data/NIA50/50-2/data/nia50_final/raw'\n",
    "labels = sorted(glob.glob(f'{src}/*/label/*.json'))\n",
    "for j, label in enumerate(tqdm(labels)):\n",
    "    scene = re.findall('\\w+', label)[-4]\n",
    "    frame = re.findall('\\w+', label)[-2]\n",
    "\n",
    "    with open(label, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    if len(json_data)==0:\n",
    "        no_label.append(scene)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "for i in dict(Counter(no_label)).items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for i in dict(Counter(no_label)).items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l, w, h 범위 확인\n",
    "np.around(dp.groupby('class').quantile(0.99)[['l', 'w', 'h']].values, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 데이터 프레임 불러오기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 584991 entries, 0 to 585023\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           584991 non-null  int64  \n",
      " 1   class        584991 non-null  object \n",
      " 2   min_x        584991 non-null  float64\n",
      " 3   min_y        584991 non-null  float64\n",
      " 4   max_x        584991 non-null  float64\n",
      " 5   max_y        584991 non-null  float64\n",
      " 6   point_x      584991 non-null  float64\n",
      " 7   point_y      584991 non-null  float64\n",
      " 8   point_z      584991 non-null  float64\n",
      " 9   l            584991 non-null  float64\n",
      " 10  w            584991 non-null  float64\n",
      " 11  h            584991 non-null  float64\n",
      " 12  rot_y        584991 non-null  float64\n",
      " 13  intrinsic    584991 non-null  object \n",
      " 14  extrinsic    584991 non-null  object \n",
      " 15  mov_point_z  584991 non-null  int64  \n",
      " 16  scene        584991 non-null  object \n",
      " 17  frame        584991 non-null  object \n",
      "dtypes: float64(11), int64(2), object(5)\n",
      "memory usage: 84.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dp = pd.read_csv('/data/NIA50/50-2/data/nia50_final/data_info.csv', index_col=0, dtype={'frame':object})\n",
    "dp.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # class 통합 1\n",
    "---\n",
    "- Small_Car, Light_Car, Car -> Car\n",
    "- SUV -> SUV_&_Van\n",
    "- Van -> SUV_&_Van\n",
    "- Small_Truck, Medium_Truck, Large_Truck -> Truck\n",
    "- Mini_Bus, Bus -> Bus\n",
    "- Special_Vehicle -> 앵커 기준으로 SUV_&_Van, Truck, Special_Vehicle로 나누기\n",
    "- Two_Wheeler -> Two_Wheeler\n",
    "- Kickboard, Adult, Kid -> Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = pd.read_csv('/data/NIA50/50-2/data/nia50_final/data_info1.csv', index_col=0, dtype={'frame':object})\n",
    "\n",
    "# class 통합\n",
    "dp.loc[(dp['class']=='Car') | (dp['class']=='Light_Car') | (dp['class']=='Small_Car'), 'class'] = 'Car'\n",
    "dp.loc[(dp['class']=='SUV') | (dp['class']=='Van'), 'class'] = 'SUV_&_Van'\n",
    "dp.loc[(dp['class']=='Adult') | (dp['class']=='Kid') | (dp['class']=='Kickboard'), 'class'] = 'Person'\n",
    "dp.loc[(dp['class']=='Small_Truck') | (dp['class']=='Medium_Truck') | (dp['class']=='Large_Truck'), 'class'] = 'Truck'\n",
    "dp.loc[(dp['class']=='Mini_Bus') | (dp['class']=='Bus'), 'class'] = 'Bus'\n",
    "\n",
    "qt = dp[['class', 'l', 'w', 'h']].groupby('class').quantile(0.99)\n",
    "dp.loc[(dp['class']=='Special_Vehicle') & (dp['l']<=qt.loc['SUV_&_Van']['l']) & (dp['w']<=qt.loc['SUV_&_Van']['w']) & (dp['h']<=qt.loc['SUV_&_Van']['h']), 'class'] = 'SUV_&_Van'\n",
    "dp.loc[(dp['class']=='Special_Vehicle') & (dp['l']>qt.loc['SUV_&_Van']['l']) & (dp['w']>qt.loc['SUV_&_Van']['w']) & (dp['h']>qt.loc['SUV_&_Van']['h'])\n",
    "        & (dp['l']<=qt.loc['Truck']['l']) & (dp['w']<=qt.loc['Truck']['w']) & (dp['h']<=qt.loc['Truck']['h']), 'class'] = 'Truck'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # class 통합 2\n",
    "---\n",
    "- Small_Car, Light_Car, Car -> Car\n",
    "- SUV -> SUV_&_Van\n",
    "- Van -> SUV_&_Van\n",
    "- Small_Truck, Medium_Truck, Large_Truck -> Truck\n",
    "- Mini_Bus, Bus -> Bus\n",
    "- Special_Vehicle -> 육안으로 확인하여 Car, SUV_&_VAN, Truck, Special_Vehicle로 나누기 (Special_Vehicle은 지게차, 포크레인, 야쿠르트 아주머니)\n",
    "- Two_Wheeler -> Two_Wheeler\n",
    "- Kickboard, Adult, Kid -> Person\n",
    "- l, w, h가 너무 작거나 큰 객체는 라벨에서 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424049 entries, 0 to 424048\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           424049 non-null  int64  \n",
      " 1   class        424049 non-null  object \n",
      " 2   min_x        424049 non-null  float64\n",
      " 3   min_y        424049 non-null  float64\n",
      " 4   max_x        424049 non-null  float64\n",
      " 5   max_y        424049 non-null  float64\n",
      " 6   point_x      424049 non-null  float64\n",
      " 7   point_y      424049 non-null  float64\n",
      " 8   point_z      424049 non-null  float64\n",
      " 9   l            424049 non-null  float64\n",
      " 10  w            424049 non-null  float64\n",
      " 11  h            424049 non-null  float64\n",
      " 12  rot_y        424049 non-null  float64\n",
      " 13  intrinsic    424049 non-null  object \n",
      " 14  extrinsic    424049 non-null  object \n",
      " 15  mov_point_z  424049 non-null  int64  \n",
      " 16  scene        424049 non-null  object \n",
      " 17  frame        424049 non-null  object \n",
      "dtypes: float64(11), int64(2), object(5)\n",
      "memory usage: 58.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dp = pd.read_csv('/data/NIA50/50-2/data/nia50_final/data_info.csv', index_col=0, dtype={'frame':object})\n",
    "\n",
    "# class 통합\n",
    "dp.loc[(dp['class']=='Car') | (dp['class']=='Light_Car') | (dp['class']=='Small_Car'), 'class'] = 'Car'\n",
    "dp.loc[(dp['class']=='SUV') | (dp['class']=='Van'), 'class'] = 'SUV_&_Van'\n",
    "dp.loc[(dp['class']=='Adult') | (dp['class']=='Kid') | (dp['class']=='Kickboard'), 'class'] = 'Person'\n",
    "dp.loc[(dp['class']=='Small_Truck') | (dp['class']=='Medium_Truck') | (dp['class']=='Large_Truck'), 'class'] = 'Truck'\n",
    "dp.loc[(dp['class']=='Mini_Bus') | (dp['class']=='Bus'), 'class'] = 'Bus'\n",
    "\n",
    "cng_sv = pd.read_csv('/data/NIA50/50-2/data/nia50_final/change_special_vehicle.txt', names=['id', 'scene', 'class', 'sub_class'])\n",
    "for id_, scene in zip(cng_sv['id'].values, cng_sv['scene'].values):\n",
    "    cng_cls = cng_sv.loc[(cng_sv['id']==id_) & (cng_sv['scene']==scene), 'class']\n",
    "    dp.loc[(dp['id']==id_) & (dp['scene']==scene) & (dp['class']=='Special_Vehicle'), 'class'] = cng_cls\n",
    "\n",
    "# 탐지 범위 제한\n",
    "dp.loc[dp['min_x'] < 0, 'min_x'] = 0\n",
    "dp.loc[dp['min_x'] > 1920, 'min_x'] = 1920\n",
    "dp.loc[dp['max_x'] < 0, 'max_x'] = 0\n",
    "dp.loc[dp['max_x'] > 1920, 'max_x'] = 1920\n",
    "dp.loc[dp['min_y'] < 0, 'min_y'] = 0\n",
    "dp.loc[dp['min_y'] > 1200, 'min_y'] = 1200\n",
    "dp.loc[dp['max_y'] < 0, 'max_y'] = 0\n",
    "dp.loc[dp['max_y'] > 1200, 'max_y'] = 1200\n",
    "drop_index = dp.loc[(dp['class']==0)| (dp['class']=='Unknown') | (dp['id'].isnull()) | \n",
    "                    (dp['min_x']-dp['max_x']==0) | (dp['min_y']-dp['max_y']==0) |\n",
    "                    (dp['point_y']>0) | (dp['point_y']<-50) | (dp['point_x']<-50) | (dp['point_x']>50)].index\n",
    "dp = dp.drop(drop_index).reset_index(drop=True)\n",
    "\n",
    "# 극단값 제거\n",
    "for class_ in dp['class'].unique():\n",
    "    min_Q = dp.loc[dp['class']==class_][['l', 'w', 'h']].quantile(0.1)\n",
    "    max_Q = dp.loc[dp['class']==class_][['l', 'w', 'h']].quantile(0.99)\n",
    "    drop_index = dp.loc[(dp['class']==class_) & \n",
    "                        ((dp['l']<min_Q[0]) | (dp['w']<min_Q[1]) | (dp['h']<min_Q[2]) | (dp['l']>max_Q[0]) | (dp['w']>max_Q[1]) | (dp['h']>max_Q[2]))].index\n",
    "    dp = dp.drop(drop_index)\n",
    "\n",
    "dp = dp.reset_index(drop=True)\n",
    "dp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame 모자란 scene 확인\n",
    "check = []\n",
    "for scene in dp['scene'].unique():\n",
    "    frame = dp.loc[dp['scene']==scene, 'frame']\n",
    "    frame_num = len(set(frame))\n",
    "    if frame_num < 10:\n",
    "        check.append({'scene': scene, 'frame':set(frame)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 극단값 제거 (IQR 사용)\n",
    "# # dp_Q = dp.groupby('class').quantile([0.25, 0.75])[['l', 'w', 'h']]\n",
    "# for class_ in dp['class'].unique()[2:4]:\n",
    "#     Q1 = dp.loc[dp['class']==class_][['l', 'w', 'h']].quantile(0.25)\n",
    "#     Q3 = dp.loc[dp['class']==class_][['l', 'w', 'h']].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "\n",
    "#     outlier = IQR * 1.5\n",
    "#     min_outlier = Q1 - outlier\n",
    "#     max_outlier = Q3 + outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bus</th>\n",
       "      <td>12.832408</td>\n",
       "      <td>3.367793</td>\n",
       "      <td>3.823763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car</th>\n",
       "      <td>5.084260</td>\n",
       "      <td>2.181355</td>\n",
       "      <td>1.815112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Person</th>\n",
       "      <td>1.192694</td>\n",
       "      <td>1.097000</td>\n",
       "      <td>1.926561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUV_&amp;_Van</th>\n",
       "      <td>5.179612</td>\n",
       "      <td>2.243432</td>\n",
       "      <td>2.116742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Special_Vehicle</th>\n",
       "      <td>10.436841</td>\n",
       "      <td>3.283156</td>\n",
       "      <td>4.351732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truck</th>\n",
       "      <td>10.408181</td>\n",
       "      <td>2.894754</td>\n",
       "      <td>3.771813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two_Wheeler</th>\n",
       "      <td>2.695790</td>\n",
       "      <td>1.143500</td>\n",
       "      <td>1.822978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         l         w         h\n",
       "class                                         \n",
       "Bus              12.832408  3.367793  3.823763\n",
       "Car               5.084260  2.181355  1.815112\n",
       "Person            1.192694  1.097000  1.926561\n",
       "SUV_&_Van         5.179612  2.243432  2.116742\n",
       "Special_Vehicle  10.436841  3.283156  4.351732\n",
       "Truck            10.408181  2.894754  3.771813\n",
       "Two_Wheeler       2.695790  1.143500  1.822978"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.groupby('class').max()[['l', 'w', 'h']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # yolov5\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4472/4472 [1:19:58<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "src = '/data/NIA50/50-2/data/nia50_final/raw'\n",
    "dst = '/data/NIA50/50-2/data/nia50_final/yolov5_integ_2'\n",
    "\n",
    "os.makedirs(f'{dst}/labels', exist_ok=True)\n",
    "os.makedirs(f'{dst}/images', exist_ok=True)\n",
    "os.makedirs(f'{dst}/ImageSets', exist_ok=True)\n",
    "os.makedirs(f'{dst}/test_images', exist_ok=True)\n",
    "\n",
    "class_num = {'Car': 0,\n",
    "             'SUV_&_Van': 1,\n",
    "             'Truck': 2,\n",
    "             'Bus': 3,\n",
    "             'Special_Vehicle': 4,\n",
    "             'Two_Wheeler': 5,\n",
    "             'Person': 6}\n",
    "\n",
    "dat_typs = []\n",
    "\n",
    "scenes = dp['scene'].unique()\n",
    "for scene in tqdm(scenes):\n",
    "    dat_typs.append(re.findall('[a-zA-Z]+_[A-Z]_[A-Z]', scene)[0])\n",
    "\n",
    "    frames = dp.loc[dp['scene']==scene, 'frame'].unique()\n",
    "    for frame in frames:\n",
    "\n",
    "\n",
    "        # make points\n",
    "        frame_data = dp.loc[(dp['scene']==scene) & (dp['frame']==frame)].copy()\n",
    "        frame_data['class_num'] = frame_data['class'].apply(lambda x: class_num[x])\n",
    "        xyxy_ls = frame_data[['min_x', 'min_y', 'max_x', 'max_y']].values\n",
    "        \n",
    "        xywhn_ls = []\n",
    "        for xyxy in xyxy_ls:\n",
    "            xywhn = xyxy2xywhn(xyxy)\n",
    "            xywhn_ls.append(xywhn)\n",
    "        \n",
    "        frame_data[['xn', 'yn', 'wn', 'hn']] = xywhn_ls\n",
    "        frame_data[['class_num', 'xn', 'yn', 'wn', 'hn']].to_csv(f'{dst}/labels/{scene}_{frame}.txt', header=False, index=False, sep=' ')\n",
    "\n",
    "\n",
    "        # make images\n",
    "        image_src = f'{src}/{scene}/camera/camera_0/{frame}.jpg'\n",
    "        image_dst = f'{dst}/images/{scene}_{frame}.jpg'\n",
    "        shutil.copyfile(image_src, image_dst)\n",
    "\n",
    "\n",
    "# make ImageSets\n",
    "train_ls = []\n",
    "val_ls = []\n",
    "test_ls = []\n",
    "\n",
    "images = sorted(glob.glob(f'{dst}/images/*.jpg'))\n",
    "# dat_typs = set([re.findall('[a-zA-Z]+_[A-Z]_[A-Z]', scene)[0] for scene in scenes])\n",
    "for dat_typ in sorted(set(dat_typs)):\n",
    "    scenes_typ = [scene for scene in scenes if dat_typ in scene]\n",
    "    \n",
    "    train_val, test = train_test_split(scenes_typ, test_size=0.1, shuffle=False, random_state=44)\n",
    "    train, val = train_test_split(train_val, test_size=0.2, random_state=44)\n",
    "\n",
    "    for j in train:\n",
    "        for image in images:\n",
    "            if j in image:\n",
    "                train_ls.append(image)\n",
    "\n",
    "    for j in val:\n",
    "        for image in images:\n",
    "            if j in image:\n",
    "                val_ls.append(image)\n",
    "\n",
    "    for j in test:\n",
    "        for image in images:\n",
    "            if j in image:\n",
    "                test_ls.append(image)\n",
    "\n",
    "with open(f'{dst}/ImageSets/train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(train_ls)))\n",
    "    \n",
    "with open(f'{dst}/ImageSets/val.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(val_ls)))\n",
    "\n",
    "with open(f'{dst}/ImageSets/test.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(test_ls)))\n",
    "\n",
    "\n",
    "# make test_images\n",
    "with open(f'{dst}/ImageSets/test.txt', 'r') as f:\n",
    "    test_images = [j.replace('\\n', '') for j in f.readlines()]\n",
    "\n",
    "for image in test_images:\n",
    "    if os.path.exists(image) == True:\n",
    "        shutil.move(image, f'{dst}/test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # pvrcnn\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '/data/NIA50/50-2/data/nia50_final/raw'\n",
    "dst = '/data/NIA50/50-2/data/nia50_final/pvrcnn_integ_2'\n",
    "\n",
    "os.makedirs(f'{dst}/labels', exist_ok=True)\n",
    "os.makedirs(f'{dst}/points', exist_ok=True)\n",
    "os.makedirs(f'{dst}/ImageSets', exist_ok=True)\n",
    "\n",
    "# # Z축 이동을 위해서 calib와 매칭하여 이동범위 지정\n",
    "# calib_ls = []\n",
    "# # scenes = []\n",
    "# calibs = sorted(glob.glob(f'{src}/*/calib/camera/camera_0.json'))\n",
    "# for calib in calibs:\n",
    "#     scene = re.findall('[a-zA-Z0-9_]+', calib)[-5]\n",
    "#     with open(calib, 'r') as f:\n",
    "#         calib = json.load(f)\n",
    "#     if calib['extrinsic'] not in calib_ls:\n",
    "#         calib_ls.append(calib['extrinsic'])\n",
    "#         # scenes.append(scene)    \n",
    "# calib_typ = {'typ1': {'calib': calib_ls[0], 'mov_zpoint': 14},\n",
    "#              'typ2': {'calib': calib_ls[1], 'mov_zpoint': 13},\n",
    "#              'typ3': {'calib': calib_ls[2], 'mov_zpoint': 0},\n",
    "#              'typ4': {'calib': calib_ls[3], 'mov_zpoint': -20}}\n",
    "\n",
    "dat_typs = []\n",
    "\n",
    "scenes = dp['scene'].unique()\n",
    "for scene in tqdm(scenes):\n",
    "    dat_typs.append(re.findall('[a-zA-Z]+_[A-Z]_[A-Z]', scene)[0])\n",
    "\n",
    "    # with open(f'{src}/{scene}/calib/camera/camera_0.json', 'r') as f:\n",
    "    #     calib = json.load(f)\n",
    "\n",
    "    # for typ in ['typ1', 'typ2', 'typ3', 'typ4']:\n",
    "    #     if calib['extrinsic'] == calib_typ[typ]['calib']:\n",
    "    #         mov_zpoint = calib_typ[typ]['mov_zpoint']\n",
    "\n",
    "    frames = dp.loc[dp['scene']==scene, 'frame'].unique()\n",
    "    for frame in frames:\n",
    "\n",
    "\n",
    "        # make labels\n",
    "        frame_data = dp.loc[(dp['scene']==scene) & (dp['frame']==frame)].copy()\n",
    "        frame_data[['point_x', 'point_y', 'point_z', 'l', 'w', 'h', 'rot_y', 'class']].to_csv(f'{dst}/labels/{scene}_{frame}.txt', header=False, index=False, sep=' ')\n",
    "\n",
    "\n",
    "        # make points\n",
    "        point_src = f'{src}/{scene}/lidar/{frame}.pcd'\n",
    "        point_dst = f'{dst}/points/{scene}_{frame}.npy'\n",
    "\n",
    "        pcd = o3d.t.io.read_point_cloud(point_src)\n",
    "        positions = pcd.point.positions.numpy()\n",
    "        intensity = pcd.point.intensity.numpy()\n",
    "        positions[:, 2] += frame_data['mov_point_z'].values[0]\n",
    "\n",
    "        pcd = np.concatenate((positions, intensity), axis = 1)\n",
    "        # pcd 범위 자르기\n",
    "        pcd = pcd[np.where((pcd[:, 0]>=-50) & (pcd[:, 0]<=50) & (pcd[:, 1]<=0) & (pcd[:, 1]>=-50) & (pcd[:, 2]>=-4) & (pcd[:, 2]<=8))]\n",
    "        np.save(point_dst, pcd)\n",
    "\n",
    "\n",
    "# make ImageSets\n",
    "train_ls = []\n",
    "val_ls = []\n",
    "test_ls = []\n",
    "\n",
    "points = sorted(glob.glob(f'{dst}/points/*.npy'))\n",
    "for dat_typ in sorted(set(dat_typs)):\n",
    "    # images_typ = [image for image in images if dat_typ in image]\n",
    "    scenes_typ = [scene for scene in scenes if dat_typ in scene]\n",
    "    \n",
    "    train_val, test = train_test_split(scenes_typ, test_size=0.1, shuffle=False, random_state=44)\n",
    "    train, val = train_test_split(train_val, test_size=0.2, random_state=44)\n",
    "\n",
    "    for j in train:\n",
    "        for point in points:\n",
    "            if j in point:\n",
    "                point = re.findall('[a-zA-Z0-9_]+', point)[-2]\n",
    "                train_ls.append(point)\n",
    "\n",
    "    for j in val:\n",
    "        for point in points:\n",
    "            if j in point:\n",
    "                point = re.findall('[a-zA-Z0-9_]+', point)[-2]\n",
    "                val_ls.append(point)\n",
    "\n",
    "    for j in test:\n",
    "        for point in points:\n",
    "            if j in point:\n",
    "                point = re.findall('[a-zA-Z0-9_]+', point)[-2]\n",
    "                test_ls.append(point)\n",
    "\n",
    "with open(f'{dst}/ImageSets/train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(train_ls)))\n",
    "    \n",
    "with open(f'{dst}/ImageSets/val.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(val_ls)))\n",
    "\n",
    "with open(f'{dst}/ImageSets/test.txt', 'w') as f:\n",
    "    f.write('\\n'.join(sorted(test_ls)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # deepfusionmot\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424049 entries, 0 to 424048\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           424049 non-null  int64  \n",
      " 1   class        424049 non-null  object \n",
      " 2   min_x        424049 non-null  float64\n",
      " 3   min_y        424049 non-null  float64\n",
      " 4   max_x        424049 non-null  float64\n",
      " 5   max_y        424049 non-null  float64\n",
      " 6   point_x      424049 non-null  float64\n",
      " 7   point_y      424049 non-null  float64\n",
      " 8   point_z      424049 non-null  float64\n",
      " 9   l            424049 non-null  float64\n",
      " 10  w            424049 non-null  float64\n",
      " 11  h            424049 non-null  float64\n",
      " 12  rot_y        424049 non-null  float64\n",
      " 13  intrinsic    424049 non-null  object \n",
      " 14  extrinsic    424049 non-null  object \n",
      " 15  mov_point_z  424049 non-null  int64  \n",
      " 16  scene        424049 non-null  object \n",
      " 17  frame        424049 non-null  object \n",
      "dtypes: float64(11), int64(2), object(5)\n",
      "memory usage: 58.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3D_pvrcnn 데이터 프레임 생성 중: 100%|██████████| 4713/4713 [08:03<00:00,  9.76it/s]\n",
      "deepfusionmot 데이터 생성 중: 100%|██████████| 476/476 [05:01<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "src = '/data/NIA50/50-2/data/nia50_final/raw'\n",
    "dst = '/data/NIA50/50-2/data/nia50_final/deepfusionmot_integ_2'\n",
    "\n",
    "src_2d_result = '/data/NIA50/50-2/result/yolov5_integ_2/test_epoch11'\n",
    "src_3d_result = '/data/NIA50/50-2/result/pvrcnn_integ_2/test_epoch7/eval'\n",
    "src_scenes = '/data/NIA50/50-2/data/nia50_final/pvrcnn_integ_2/ImageSets/test.txt'\n",
    "\n",
    "os.makedirs(f'{dst}/2D_yolov5', exist_ok=True)\n",
    "os.makedirs(f'{dst}/3D_pvrcnn', exist_ok=True)\n",
    "os.makedirs(f'{dst}/calib', exist_ok=True)\n",
    "os.makedirs(f'{dst}/image_02', exist_ok=True)\n",
    "\n",
    "\n",
    "# make 3D_pvrcnn dataframe\n",
    "with open(f'{src_3d_result}/result.pkl', 'rb') as f:\n",
    "    results = pkl.load(f)\n",
    "\n",
    "frame_df_ls = []\n",
    "for i, result in enumerate(tqdm(results, desc='3D_pvrcnn 데이터 프레임 생성 중')):\n",
    "        \n",
    "    scene_frame = result['frame_id']\n",
    "    scene_ls = [scene_frame[:-5]] * len(result['name'])\n",
    "    frame_ls = [scene_frame[-4:]] * len(result['name'])\n",
    "    class_num_ls = result['pred_labels']\n",
    "    scores = result['score']\n",
    "    x_ls = result['boxes_lidar'][:, 0]\n",
    "    y_ls = result['boxes_lidar'][:, 1]\n",
    "    z_ls = result['boxes_lidar'][:, 2]\n",
    "    l_ls = result['boxes_lidar'][:, 3]\n",
    "    w_ls = result['boxes_lidar'][:, 4]\n",
    "    h_ls = result['boxes_lidar'][:, 5]\n",
    "    rot_y_ls = result['boxes_lidar'][:, 6]\n",
    "    extrinsic = json.loads(dp.loc[dp['scene']==scene_ls[0], 'extrinsic'].values[0])\n",
    "    extrinsic = np.asarray(extrinsic).reshape(4, 4)\n",
    "    intrinsic = json.loads(dp.loc[dp['scene']==scene_ls[0], 'intrinsic'].values[0])\n",
    "    intrinsic = np.asarray(intrinsic).reshape(3, 4)\n",
    "\n",
    "    x1_ls, y1_ls, x2_ls, y2_ls = [], [], [], []\n",
    "    for x, y, z, l, w, h, rot_y in zip(x_ls, y_ls, z_ls, l_ls, w_ls, h_ls, rot_y_ls):\n",
    "        x1, y1, x2, y2 = xyz2xyxy(x, y, z, l, w, h, rot_y, extrinsic, intrinsic)\n",
    "        x1_ls.append(x1)\n",
    "        y1_ls.append(y1)\n",
    "        x2_ls.append(x2)\n",
    "        y2_ls.append(y2)\n",
    "\n",
    "    data = {'scene': scene_ls,\n",
    "            'frame': frame_ls, \n",
    "            'class_num': class_num_ls, \n",
    "            'x1': x1_ls, \n",
    "            'y1': y1_ls, \n",
    "            'x2': x2_ls, \n",
    "            'y2': y2_ls, \n",
    "            'score': scores, \n",
    "            'h': h_ls, \n",
    "            'w': w_ls, \n",
    "            'l': l_ls, \n",
    "            'x': x_ls, \n",
    "            'y': y_ls, \n",
    "            'z': z_ls, \n",
    "            'rot_y': rot_y_ls}\n",
    "    globals()[f'frame_df{i}'] = pd.DataFrame(data=data)\n",
    "    frame_df_ls.append(globals()[f'frame_df{i}'])\n",
    "result_df = pd.concat(frame_df_ls)\n",
    "result_df['frame'] = result_df['frame'].astype(int)\n",
    "result_df['alpha'] = 0\n",
    "result_df.loc[result_df['x1'] < 0, 'x1'] = 0\n",
    "result_df.loc[result_df['x1'] > 1920, 'x1'] = 1920\n",
    "result_df.loc[result_df['x2'] < 0, 'x2'] = 0\n",
    "result_df.loc[result_df['x2'] > 1920, 'x2'] = 1920\n",
    "result_df.loc[result_df['y1'] < 0, 'y1'] = 0\n",
    "result_df.loc[result_df['y1'] > 1200, 'y1'] = 1200\n",
    "result_df.loc[result_df['y2'] < 0, 'y2'] = 0\n",
    "result_df.loc[result_df['y2'] > 1200, 'y2'] = 1200\n",
    "result_df = result_df.loc[(result_df['x1']-result_df['x2']!=0) & (result_df['y1']-result_df['y2']!=0)]\n",
    "\n",
    "\n",
    "# test scenes 불러오기\n",
    "with open(src_scenes, 'r') as f:\n",
    "    scenes = [re.sub('\\n', '', i)[:-5] for i in f.readlines()]\n",
    "    scenes = sorted(list(set(scenes)))\n",
    "for scene in tqdm(scenes, desc='deepfusionmot 데이터 생성 중'):\n",
    "\n",
    "\n",
    "    # make calib\n",
    "    extrinsic = json.loads(dp.loc[dp['scene']==scene, 'extrinsic'].values[0])[:12]\n",
    "    intrinsic = json.loads(dp.loc[dp['scene']==scene, 'intrinsic'].values[0])\n",
    "    # kitti label 형태로 변환\n",
    "    p2 = intrinsic\n",
    "    R0_rect = np.eye(3).reshape(-1).tolist()\n",
    "    Tr_velo_to_cam = extrinsic\n",
    "    Tr_imu_to_velo = np.zeros((12)).tolist()\n",
    "\n",
    "    calib_kitti =  ['P0: '+list2str(p2), \n",
    "                    'P1: '+list2str(p2), \n",
    "                    'P2: '+list2str(p2), \n",
    "                    'P3: '+list2str(p2), \n",
    "                    'R0_rect: '+list2str(R0_rect), \n",
    "                    'Tr_velo_to_cam: '+list2str(Tr_velo_to_cam), \n",
    "                    'Tr_imu_to_velo: '+list2str(Tr_imu_to_velo)]\n",
    "\n",
    "    with open(f'{dst}/calib/{scene}.txt', 'w') as f:\n",
    "        f.write('\\n'.join(calib_kitti))\n",
    "\n",
    "\n",
    "    # make 2D_yolov5\n",
    "    w = 1920\n",
    "    h = 1200\n",
    "    labels = sorted(glob.glob(f'{src_2d_result}/labels/{scene}*.txt'))\n",
    "    label_df = pd.DataFrame()\n",
    "    for label in labels:\n",
    "        # with open(label, 'r') as f:\n",
    "        #     bbox = [re.sub('\\n', '', j) for j in f.readlines()]\n",
    "        frame_df = pd.read_csv(label, header=None, sep=' ')\n",
    "        frame_df.columns = ['class', 'x', 'y', 'w', 'h', 'conf']\n",
    "        frame_df['frame'] = int(re.findall('[0-9]+', label)[-1])\n",
    "        frame_df['class'] += 1\n",
    "        frame_df['xmin'] = (frame_df['x'] - frame_df['w']/2) * w\n",
    "        frame_df['ymin'] = (frame_df['y'] - frame_df['h']/2) * h\n",
    "        frame_df['xmax'] = (frame_df['x'] + frame_df['w']/2) * w\n",
    "        frame_df['ymax'] = (frame_df['y'] + frame_df['h']/2) * h\n",
    "\n",
    "        label_df = pd.concat((label_df, frame_df[['frame', 'class', 'xmin', 'ymin', 'xmax', 'ymax', 'conf']]), axis=0)\n",
    "    label_df[['xmin', 'ymin', 'xmax', 'ymax']] = label_df[['xmin', 'ymin', 'xmax', 'ymax']].apply(lambda x: np.around(x))\n",
    "    label_df.to_csv(f'{dst}/2D_yolov5/{scene}.txt', index=None, header=None, sep=',')\n",
    "\n",
    "\n",
    "    # make 3D_pvrcnn\n",
    "    result_df.loc[result_df['scene']==scene].iloc[:, 1:].to_csv(f'{dst}/3D_pvrcnn/{scene}.txt', index=None, header=None, sep=',')\n",
    "\n",
    "    \n",
    "    # make image_02\n",
    "    img_src = f'{src}/{scene}/camera/camera_0'\n",
    "    shutil.copytree(img_src, f'{dst}/image_02/{scene}', dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # TrackEval\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '/data/NIA50/50-2/result/deepfusionmot_integ_2'\n",
    "dst = '/data/NIA50/50-2/data/nia50_final/trackeval_integ_2_temp'\n",
    "\n",
    "os.makedirs(f'{dst}/gt/label_02', exist_ok=True)\n",
    "os.makedirs(f'{dst}/trackers/label_02', exist_ok=True)\n",
    "\n",
    "scenes = sorted(os.listdir(f'{src}/image'))\n",
    "\n",
    "for scene in scenes:\n",
    "\n",
    "    # make gt, evaluate_tracking.seqmap.training\n",
    "    seqmap = [f'{scene} empty 0000 0010' for scene in scenes]\n",
    "    seqmap[0] = re.sub('0000', '0001', seqmap[0])\n",
    "    with open(f'{dst}/gt/evaluate_tracking.seqmap.training', 'w') as f:\n",
    "        f.write('\\n'.join(seqmap))\n",
    "\n",
    "    \n",
    "    # make gt, label_02\n",
    "    scene_df = dp.loc[dp['scene']==scene].copy()\n",
    "    scene_df[['truncated', 'occluded', 'alpha']]= 0\n",
    "    scene_df['frame'] = scene_df['frame'].astype(int)\n",
    "    scene_df[['frame']]\n",
    "    scene_df = scene_df[['frame', 'id', 'class', 'truncated', 'occluded', 'alpha', 'min_x', 'min_y', 'max_x', 'max_y', 'h', 'w', 'l', 'point_x', 'point_y', 'point_z', 'rot_y']]\n",
    "    dropped_duple_idx = scene_df[['frame', 'id']].drop_duplicates().index\n",
    "    scene_df = scene_df.loc[dropped_duple_idx].copy()\n",
    "    scene_df.to_csv(f'{dst}/gt/label_02/{scene}.txt', index=None, header=None, sep=' ')\n",
    "\n",
    "\n",
    "    # make trakers, label_02\n",
    "    if os.path.isfile(f'{src}/data/{scene}.txt')==False:\n",
    "        null_data = '0 0 None 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'\n",
    "        with open(f'{dst}/trackers/label_02/{scene}.txt', 'w') as f:\n",
    "            f.write(null_data)\n",
    "    else:\n",
    "        shutil.copy(f'{src}/data/{scene}.txt', f'{dst}/trackers/label_02/{scene}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcat = glob.glob('/data/NIA50/50-2/result/trackeval_integ_2/label_02/*.txt')\n",
    "\n",
    "allcat_ls = []\n",
    "for cat in allcat:\n",
    "    cat_name = re.findall('[a-z_&]+_summary', cat)[0]\n",
    "    cat_name = re.sub('_summary', '', cat_name)\n",
    "    cat_df = pd.read_csv(cat, sep=' ')\n",
    "    cat_df.index = [cat_name]\n",
    "\n",
    "    allcat_ls.append(cat_df)\n",
    "\n",
    "allcat_df = pd.concat(allcat_ls, axis=0)\n",
    "allcat_df = allcat_df.iloc[1:, :][['HOTA', 'MOTA', \n",
    "                                    'DetA', 'AssA', 'DetRe', 'DetPr', 'LocA', 'OWTA',\n",
    "                                    'MOTP', 'MODA',\n",
    "                                    'sMOTA', 'IDF1', 'IDR', 'IDP', 'IDTP', 'IDFN', 'IDFP', 'Dets', 'GT_Dets', 'IDs', 'GT_IDs']]\n",
    "allcat_df.to_csv(f'/data/NIA50/50-2/result/trackeval_integ_2/allcat_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOTA</th>\n",
       "      <th>MOTA</th>\n",
       "      <th>DetA</th>\n",
       "      <th>AssA</th>\n",
       "      <th>DetRe</th>\n",
       "      <th>DetPr</th>\n",
       "      <th>LocA</th>\n",
       "      <th>OWTA</th>\n",
       "      <th>MOTP</th>\n",
       "      <th>MODA</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF1</th>\n",
       "      <th>IDR</th>\n",
       "      <th>IDP</th>\n",
       "      <th>IDTP</th>\n",
       "      <th>IDFN</th>\n",
       "      <th>IDFP</th>\n",
       "      <th>Dets</th>\n",
       "      <th>GT_Dets</th>\n",
       "      <th>IDs</th>\n",
       "      <th>GT_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>two_wheeler</th>\n",
       "      <td>64.862</td>\n",
       "      <td>26.908</td>\n",
       "      <td>48.067</td>\n",
       "      <td>88.252</td>\n",
       "      <td>76.694</td>\n",
       "      <td>53.946</td>\n",
       "      <td>89.041</td>\n",
       "      <td>82.075</td>\n",
       "      <td>88.144</td>\n",
       "      <td>28.012</td>\n",
       "      <td>...</td>\n",
       "      <td>69.320</td>\n",
       "      <td>83.936</td>\n",
       "      <td>59.040</td>\n",
       "      <td>1672</td>\n",
       "      <td>320</td>\n",
       "      <td>1160</td>\n",
       "      <td>2832</td>\n",
       "      <td>1992</td>\n",
       "      <td>588</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <td>60.885</td>\n",
       "      <td>32.737</td>\n",
       "      <td>42.388</td>\n",
       "      <td>87.753</td>\n",
       "      <td>51.191</td>\n",
       "      <td>69.741</td>\n",
       "      <td>93.209</td>\n",
       "      <td>66.968</td>\n",
       "      <td>93.064</td>\n",
       "      <td>33.760</td>\n",
       "      <td>...</td>\n",
       "      <td>60.472</td>\n",
       "      <td>52.430</td>\n",
       "      <td>71.429</td>\n",
       "      <td>410</td>\n",
       "      <td>372</td>\n",
       "      <td>164</td>\n",
       "      <td>574</td>\n",
       "      <td>782</td>\n",
       "      <td>122</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suv_&amp;_van</th>\n",
       "      <td>63.876</td>\n",
       "      <td>36.891</td>\n",
       "      <td>48.943</td>\n",
       "      <td>83.844</td>\n",
       "      <td>62.512</td>\n",
       "      <td>68.017</td>\n",
       "      <td>93.023</td>\n",
       "      <td>72.287</td>\n",
       "      <td>93.088</td>\n",
       "      <td>38.324</td>\n",
       "      <td>...</td>\n",
       "      <td>66.231</td>\n",
       "      <td>63.550</td>\n",
       "      <td>69.147</td>\n",
       "      <td>8205</td>\n",
       "      <td>4706</td>\n",
       "      <td>3661</td>\n",
       "      <td>11866</td>\n",
       "      <td>12911</td>\n",
       "      <td>2181</td>\n",
       "      <td>1856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_vehicle</th>\n",
       "      <td>34.584</td>\n",
       "      <td>-162.920</td>\n",
       "      <td>13.805</td>\n",
       "      <td>87.072</td>\n",
       "      <td>43.191</td>\n",
       "      <td>16.625</td>\n",
       "      <td>87.742</td>\n",
       "      <td>61.207</td>\n",
       "      <td>86.431</td>\n",
       "      <td>-162.140</td>\n",
       "      <td>...</td>\n",
       "      <td>26.705</td>\n",
       "      <td>48.042</td>\n",
       "      <td>18.492</td>\n",
       "      <td>184</td>\n",
       "      <td>199</td>\n",
       "      <td>811</td>\n",
       "      <td>995</td>\n",
       "      <td>383</td>\n",
       "      <td>232</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>65.996</td>\n",
       "      <td>42.191</td>\n",
       "      <td>50.556</td>\n",
       "      <td>86.756</td>\n",
       "      <td>62.656</td>\n",
       "      <td>70.545</td>\n",
       "      <td>92.356</td>\n",
       "      <td>73.587</td>\n",
       "      <td>92.035</td>\n",
       "      <td>43.819</td>\n",
       "      <td>...</td>\n",
       "      <td>68.283</td>\n",
       "      <td>64.465</td>\n",
       "      <td>72.582</td>\n",
       "      <td>11206</td>\n",
       "      <td>6177</td>\n",
       "      <td>4233</td>\n",
       "      <td>15439</td>\n",
       "      <td>17383</td>\n",
       "      <td>2637</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truck</th>\n",
       "      <td>44.395</td>\n",
       "      <td>-30.327</td>\n",
       "      <td>23.880</td>\n",
       "      <td>83.107</td>\n",
       "      <td>41.168</td>\n",
       "      <td>35.726</td>\n",
       "      <td>91.116</td>\n",
       "      <td>58.347</td>\n",
       "      <td>92.308</td>\n",
       "      <td>-29.913</td>\n",
       "      <td>...</td>\n",
       "      <td>39.128</td>\n",
       "      <td>42.108</td>\n",
       "      <td>36.542</td>\n",
       "      <td>915</td>\n",
       "      <td>1258</td>\n",
       "      <td>1589</td>\n",
       "      <td>2504</td>\n",
       "      <td>2173</td>\n",
       "      <td>568</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   HOTA     MOTA    DetA    AssA   DetRe   DetPr    LocA  \\\n",
       "two_wheeler      64.862   26.908  48.067  88.252  76.694  53.946  89.041   \n",
       "bus              60.885   32.737  42.388  87.753  51.191  69.741  93.209   \n",
       "suv_&_van        63.876   36.891  48.943  83.844  62.512  68.017  93.023   \n",
       "special_vehicle  34.584 -162.920  13.805  87.072  43.191  16.625  87.742   \n",
       "car              65.996   42.191  50.556  86.756  62.656  70.545  92.356   \n",
       "truck            44.395  -30.327  23.880  83.107  41.168  35.726  91.116   \n",
       "\n",
       "                   OWTA    MOTP     MODA  ...    IDF1     IDR     IDP   IDTP  \\\n",
       "two_wheeler      82.075  88.144   28.012  ...  69.320  83.936  59.040   1672   \n",
       "bus              66.968  93.064   33.760  ...  60.472  52.430  71.429    410   \n",
       "suv_&_van        72.287  93.088   38.324  ...  66.231  63.550  69.147   8205   \n",
       "special_vehicle  61.207  86.431 -162.140  ...  26.705  48.042  18.492    184   \n",
       "car              73.587  92.035   43.819  ...  68.283  64.465  72.582  11206   \n",
       "truck            58.347  92.308  -29.913  ...  39.128  42.108  36.542    915   \n",
       "\n",
       "                 IDFN  IDFP   Dets  GT_Dets   IDs  GT_IDs  \n",
       "two_wheeler       320  1160   2832     1992   588     269  \n",
       "bus               372   164    574      782   122     184  \n",
       "suv_&_van        4706  3661  11866    12911  2181    1856  \n",
       "special_vehicle   199   811    995      383   232      50  \n",
       "car              6177  4233  15439    17383  2637    2651  \n",
       "truck            1258  1589   2504     2173   568     331  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcat_df.iloc[1:, :][['HOTA', 'MOTA', \n",
    "                       'DetA', 'AssA', 'DetRe', 'DetPr', 'LocA', 'OWTA',\n",
    "                       'MOTP', 'MODA',\n",
    "                       'sMOTA', 'IDF1', 'IDR', 'IDP', 'IDTP', 'IDFN', 'IDFP', 'Dets', 'GT_Dets', 'IDs', 'GT_IDs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOTA</th>\n",
       "      <th>MOTA</th>\n",
       "      <th>DetA</th>\n",
       "      <th>AssA</th>\n",
       "      <th>DetRe</th>\n",
       "      <th>DetPr</th>\n",
       "      <th>LocA</th>\n",
       "      <th>OWTA</th>\n",
       "      <th>MOTP</th>\n",
       "      <th>MODA</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF1</th>\n",
       "      <th>IDR</th>\n",
       "      <th>IDP</th>\n",
       "      <th>IDTP</th>\n",
       "      <th>IDFN</th>\n",
       "      <th>IDFP</th>\n",
       "      <th>Dets</th>\n",
       "      <th>GT_Dets</th>\n",
       "      <th>IDs</th>\n",
       "      <th>GT_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>two_wheeler</th>\n",
       "      <td>59.317</td>\n",
       "      <td>25.8930</td>\n",
       "      <td>41.7030</td>\n",
       "      <td>85.153</td>\n",
       "      <td>59.023</td>\n",
       "      <td>56.021</td>\n",
       "      <td>88.812</td>\n",
       "      <td>70.685</td>\n",
       "      <td>87.939</td>\n",
       "      <td>25.893</td>\n",
       "      <td>...</td>\n",
       "      <td>63.913</td>\n",
       "      <td>65.625</td>\n",
       "      <td>62.288</td>\n",
       "      <td>147</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "      <td>236</td>\n",
       "      <td>224</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <td>20.854</td>\n",
       "      <td>-145.5800</td>\n",
       "      <td>8.1101</td>\n",
       "      <td>53.746</td>\n",
       "      <td>21.697</td>\n",
       "      <td>11.391</td>\n",
       "      <td>89.894</td>\n",
       "      <td>34.117</td>\n",
       "      <td>90.311</td>\n",
       "      <td>-144.220</td>\n",
       "      <td>...</td>\n",
       "      <td>14.520</td>\n",
       "      <td>21.088</td>\n",
       "      <td>11.071</td>\n",
       "      <td>31</td>\n",
       "      <td>116</td>\n",
       "      <td>249</td>\n",
       "      <td>280</td>\n",
       "      <td>147</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suv_&amp;_van</th>\n",
       "      <td>71.041</td>\n",
       "      <td>56.1710</td>\n",
       "      <td>57.5190</td>\n",
       "      <td>88.624</td>\n",
       "      <td>67.494</td>\n",
       "      <td>76.818</td>\n",
       "      <td>91.560</td>\n",
       "      <td>77.119</td>\n",
       "      <td>91.010</td>\n",
       "      <td>56.882</td>\n",
       "      <td>...</td>\n",
       "      <td>76.237</td>\n",
       "      <td>71.610</td>\n",
       "      <td>81.503</td>\n",
       "      <td>1410</td>\n",
       "      <td>559</td>\n",
       "      <td>320</td>\n",
       "      <td>1730</td>\n",
       "      <td>1969</td>\n",
       "      <td>242</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_vehicle</th>\n",
       "      <td>27.825</td>\n",
       "      <td>14.7830</td>\n",
       "      <td>18.8590</td>\n",
       "      <td>41.366</td>\n",
       "      <td>20.229</td>\n",
       "      <td>70.494</td>\n",
       "      <td>91.101</td>\n",
       "      <td>28.831</td>\n",
       "      <td>90.665</td>\n",
       "      <td>14.783</td>\n",
       "      <td>...</td>\n",
       "      <td>33.784</td>\n",
       "      <td>21.739</td>\n",
       "      <td>75.758</td>\n",
       "      <td>25</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>115</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>70.086</td>\n",
       "      <td>55.3460</td>\n",
       "      <td>57.3480</td>\n",
       "      <td>86.430</td>\n",
       "      <td>65.612</td>\n",
       "      <td>79.454</td>\n",
       "      <td>92.036</td>\n",
       "      <td>75.121</td>\n",
       "      <td>91.640</td>\n",
       "      <td>56.918</td>\n",
       "      <td>...</td>\n",
       "      <td>74.302</td>\n",
       "      <td>67.830</td>\n",
       "      <td>82.140</td>\n",
       "      <td>2157</td>\n",
       "      <td>1023</td>\n",
       "      <td>469</td>\n",
       "      <td>2626</td>\n",
       "      <td>3180</td>\n",
       "      <td>396</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truck</th>\n",
       "      <td>49.728</td>\n",
       "      <td>3.2653</td>\n",
       "      <td>31.3630</td>\n",
       "      <td>79.152</td>\n",
       "      <td>45.800</td>\n",
       "      <td>48.787</td>\n",
       "      <td>91.443</td>\n",
       "      <td>60.145</td>\n",
       "      <td>90.776</td>\n",
       "      <td>4.898</td>\n",
       "      <td>...</td>\n",
       "      <td>49.263</td>\n",
       "      <td>47.755</td>\n",
       "      <td>50.870</td>\n",
       "      <td>117</td>\n",
       "      <td>128</td>\n",
       "      <td>113</td>\n",
       "      <td>230</td>\n",
       "      <td>245</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   HOTA      MOTA     DetA    AssA   DetRe   DetPr    LocA  \\\n",
       "two_wheeler      59.317   25.8930  41.7030  85.153  59.023  56.021  88.812   \n",
       "bus              20.854 -145.5800   8.1101  53.746  21.697  11.391  89.894   \n",
       "suv_&_van        71.041   56.1710  57.5190  88.624  67.494  76.818  91.560   \n",
       "special_vehicle  27.825   14.7830  18.8590  41.366  20.229  70.494  91.101   \n",
       "car              70.086   55.3460  57.3480  86.430  65.612  79.454  92.036   \n",
       "truck            49.728    3.2653  31.3630  79.152  45.800  48.787  91.443   \n",
       "\n",
       "                   OWTA    MOTP     MODA  ...    IDF1     IDR     IDP  IDTP  \\\n",
       "two_wheeler      70.685  87.939   25.893  ...  63.913  65.625  62.288   147   \n",
       "bus              34.117  90.311 -144.220  ...  14.520  21.088  11.071    31   \n",
       "suv_&_van        77.119  91.010   56.882  ...  76.237  71.610  81.503  1410   \n",
       "special_vehicle  28.831  90.665   14.783  ...  33.784  21.739  75.758    25   \n",
       "car              75.121  91.640   56.918  ...  74.302  67.830  82.140  2157   \n",
       "truck            60.145  90.776    4.898  ...  49.263  47.755  50.870   117   \n",
       "\n",
       "                 IDFN  IDFP  Dets  GT_Dets  IDs  GT_IDs  \n",
       "two_wheeler        77    89   236      224   29      35  \n",
       "bus               116   249   280      147   50      43  \n",
       "suv_&_van         559   320  1730     1969  242     289  \n",
       "special_vehicle    90     8    33      115   11      16  \n",
       "car              1023   469  2626     3180  396     539  \n",
       "truck             128   113   230      245   46      53  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcat_df.iloc[1:, :][['HOTA', 'MOTA', \n",
    "                       'DetA', 'AssA', 'DetRe', 'DetPr', 'LocA', 'OWTA',\n",
    "                       'MOTP', 'MODA',\n",
    "                       'sMOTA', 'IDF1', 'IDR', 'IDP', 'IDTP', 'IDFN', 'IDFP', 'Dets', 'GT_Dets', 'IDs', 'GT_IDs']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spiner310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746d95b724613cc31ae9ea1c95fce8e51ec3ee7393c1b2a647745f061ae2ccda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
